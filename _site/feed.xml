<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-02-29T21:17:22+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">kelpin’s blog</title><subtitle>kelpin의 블로그입니다. 학습했던 것을 정리해 블로그에 올리고 있습니다.</subtitle><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><entry><title type="html">Kafka 공식문서</title><link href="http://localhost:4000/kafka/kafka_official_documents/" rel="alternate" type="text/html" title="Kafka 공식문서" /><published>2020-02-24T00:00:00+09:00</published><updated>2020-02-24T00:00:00+09:00</updated><id>http://localhost:4000/kafka/kafka_official_documents</id><content type="html" xml:base="http://localhost:4000/kafka/kafka_official_documents/">&lt;h1 id=&quot;목적&quot;&gt;목적&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;이 글은 Kafka 공식 문서를 번역하기 위해 작성한 글이다. 전체 문서 번역이 아닌 일부분 중요하다고 생각하는 부분에 대해서 작성을 진행한다. 번역하기 어려운 기술용어에 대해서는 원문이 의미 전달에 더 용이할 것이라 판단해 그대로 작성한다. 이 문서는 &lt;a href=&quot;https://kafka.apache.org/documentation/&quot;&gt;Kafak 2.4.0의 공식문서&lt;/a&gt;를 기준으로 작성했다. &lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction &lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Apach Kafka는 분산 streaming platform이다. &lt;/p&gt;

&lt;p&gt;Streaming platform은 3가지 특징이 있다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Message queue 또는 Enterprise messaging system과 유사하게 Records를 Publish하고 Subscribe한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Stream of records를 Fault-tolerant(장애에 강한) 방식으로 저장한다. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Records가 발생하면 해당 Stream을 처리한다. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/kafka-apis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kafka 일반적으로 다음과 같은 두 가지 광범위한 종류의 Application에 사용된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Applications 혹은 System 간 안전하게 데이터를 얻을 수 있는 Real-time streaming data pipelines을 구축한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Streaming data를 Transform하거나 React하기 위한 Real-time streaming data pipelines을 구축한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kafka가 이런 일들을 어떻게 하는지 이해하기 위해서, Kafka의 능력을 밑바닥부터 파고들어 탐구해 보자.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;첫번째 몇 가지 Concept:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Kafka는 Cluster로 작동하며 하나 또는 하나 이상의 Server로 확장할 수 있으며, 이것은 여러 개의 데이터 센터로 확장할 수 있다. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kafka cluster는 Topic으로 streaming records를 구분해 저장한다. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;각 각의 Record는 Key, value, timestamp로 구성되어 있다. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Kafka 4개의 핵심 API:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/documentation.html#producerapi&quot;&gt;Producer API&lt;/a&gt;: Application이 하나 이상의 Topic에 Streaming record를 게시하도록 허용한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/documentation.html#consumerapi&quot;&gt;Consumer API&lt;/a&gt;: Application이 하나 이상의 Topic에 구독하고 생산된 Streaming record를 처리하도록 허용한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/documentation/streams&quot;&gt;Streams API&lt;/a&gt;: Application이 하나 이상의 Topic으로 부터 입력 Stream을 소비하고 하나 이상의 출력 Topic으로 출력 Stream을 생성하여 효과적으로 입력 Stream을 출력 Stream으로 변환한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://kafka.apache.org/documentation.html#connect&quot;&gt;Connector API&lt;/a&gt;: Topic을 기존 Application이나 데이터 시스템에 연결하는 재사용 가능한 producers, consumers을 만들어서 실행할 수 있다. 예로 관계형 DB의 커넥터는 테이블에 대한 모든 변경 사항을 캡처 할 수 있다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kafka에서 Clients와 Servers간 통신은 간단하고, 고성능이며, 언어와 관계없는 TCP Protocol를 사용한다. &lt;/p&gt;

&lt;h1 id=&quot;topics-and-logs&quot;&gt;Topics and Logs&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Topic은 Publish된 Records의 Category 혹은 Feed 이름이다. Kafka의 Topic은 항상 Multi-subscriber를 갖는다. 그것은, Topic은 쓰여진 데이터를 구독하는 0개부터 여러 개의 Consumer를 가질 수 있다는 것이다. &lt;/p&gt;

&lt;p&gt;각 각의 Topic은 다음과 같이 Kafka cluster에서 Partition된 로그를 관리한다. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/log_anatomy.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;각 각의 Partition은 정렬되어 있으며, Immutable한 record의 순서는 계속적으로 추가된다. (-구조화된 commit log로 추가된다.) Partition에 있는 Records는 각 각의 Partition에서 Unique한 식별자인 Offset을 가지고 할당된다. &lt;/p&gt;

&lt;p&gt;Kafka clster는 설정 가능한 Retention 기간을 이용해 Publish된 Records를 지속적으로 저장한다. 예를 들면, Retention 정책이 2일로 설정됬다면, Publish된 시점부터 2일 후까지는 Consuming이 가능하나 2일 이후에는 공간을 비우기 위해 삭제된다. Kafka의 성능은 데이터 크기가 일정하므로 오랫동안 데이터를 저장하는 것에 대해 문제가 되지 않는다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/log_consumer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;사실은, Consumer마다 생기는 Metadata는 Consumer의 Offset이나 위치이다. 이 Offset은 Consumer에 의해 컨트롤된다: Consumer는 Record를 읽으며 선형적으로 offset을 증가시킬 것이다. 그러나 사실, Consumer에 의해 Offset이 컨트롤되기 떄문에 예를 드는 것처럼 아무 순서나 소비할수 있다. 예를 들면, Consumer는 오래된 Offset에 대해 다시 데이터를 처리할 수 있으며 스킵하고 가장 최근의 Record와 당장 들어온 Record를 소비할 수 있다. &lt;/p&gt;

&lt;p&gt;이런 기능의 결합은 카프카 소비자가 매우 저렴(cheap)하다는 것을 의미한다. “저렴하다”라는 것은 Kafka cluster나 다른 소비자들에게 큰 영향을 미치지 않고 오락가락(come and go)할 수 있다는 것이다. 예를 들어, 기존 소비자가 소비하는 것을 변경하지 않고 어떤 토픽의 컨텐츠의 “tail” 명령어를 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;Log가 있는 Paritition들은 여러 가지 용도로 사용된다. 첫 번째로, 로그를 단일 서버에 맞는 크기 이상으로 확장할 수 있다.각 개별 Partition은 호스트하는 서버에 맞아야되지만, Topic에는 많은 Partition이 있어 임의의 양의 데이터를 다룰 수 있다. 둘째 Partition들은 병렬 처리 단위로 작동한다. &lt;/p&gt;

&lt;h1 id=&quot;분산distribution&quot;&gt;분산(Distribution)&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Log가 있는 Paritition들은 Kafka cluster에 있는 각 서버를 통해 분산되며 각 서버는 데이터를 처리하고 Partition 공유에 대한 요청을 처리한다. 각 파티션은 장애 허용을 위해 설정된 설정 가능한 수의 서버에 복제된다.&lt;/p&gt;

&lt;p&gt;각 파티션에는 리더(leader)역할을 하는 1개의 서버와 팔로워(follower) 역할을 하는 0개 이상의 서버가 있다. 리더는 팔로워(follower)가 리더를 수동적으로 복제하는 동안 파티션에 대한 모든 읽기/쓰기 요청을 처리한다. &lt;/p&gt;

&lt;p&gt;리더가 실패하면 팔로워 중 하나가 자동으로 새로운 리더가 된다. 각 서버는 일부 파티션의 리더와 다른 서버의 팔로어로 작동하므로 부하(load)가 클러스터 내에서 균형을 이뤄진다.&lt;/p&gt;

&lt;h1 id=&quot;지역-복제geo-replication&quot;&gt;지역 복제(Geo-Replication)&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Kafka Mirror-Maker는 Kafka cluster에 지역복제를 지원한다. Mirror-Maker를 사용하면 메시지들을 여러 데이터센터 혹은 다른 지역의 Cloud로 복제를 할 수 있다. 당신은 Active/passivce 시나리오를 백업과 복구를 위해 사용할 수 있다; 또는 Active/active 시나리오들을 데이터 지역성 요구사항을 지원하기 위해, 데이터를 당신의 사용자들에게 가까이 하기 위해 사용할 수 있다. &lt;/p&gt;

&lt;h1 id=&quot;생산자producers&quot;&gt;생산자(Producers)&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;생산자는 선택한 토픽에 데이터를 발행한다. 생산자는 Topic 안에 있는 Partition에 Record를 선택해 할당하는 책임을 가진다. 이것은 부하의 균형을 맞추기 위해 간단하게 Round-robin으로 실행되며 혹은 어떤 기준을 가진 특정 Partition 함수에 의해 실행될 수 있다(Record안에 있는 어떤 키를 말한다).&lt;/p&gt;

&lt;h1 id=&quot;소비자consumers&quot;&gt;소비자(Consumers)&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;소비자들은 ‘소비자 그룹’이라는 이름으로 라벨링이 되며, Topic으로 발행된 각 Record들은 구독하고 있는 소비자 그룹에 있는 하나의 소비자 객체에 전달된다. 소비자 객체는 분리된 프로세스들 혹은 분리된 기계들에 있을 수 있다. &lt;/p&gt;

&lt;p&gt;만약 소비자 객체가 같은 소비자 그룹에 있을 경우, Record들은 효과적으로 소비자 객체들에게 부하 분산될 것이다. &lt;/p&gt;

&lt;p&gt;만약 소비자 객체가 다른 소비자 그룹에 있을 경우, &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/consumer-groups.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="Kafka" /><summary type="html">이 글은 Kafka 공식 문서를 번역하기 위해 작성한 글이다. 전체 문서 번역이 아닌 일부분 중요하다고 생각하는 부분에 대해서 작성을 진행한다.</summary></entry><entry><title type="html">Linux환경에서 Process background에서 실행하는 방법, 프로세스 확인, 종료하는 방법</title><link href="http://localhost:4000/linux/how_to_running_process_in_background/" rel="alternate" type="text/html" title="Linux환경에서 Process background에서 실행하는 방법, 프로세스 확인, 종료하는 방법" /><published>2020-02-21T00:00:00+09:00</published><updated>2020-02-21T00:00:00+09:00</updated><id>http://localhost:4000/linux/how_to_running_process_in_background</id><content type="html" xml:base="http://localhost:4000/linux/how_to_running_process_in_background/">&lt;h1 id=&quot;목적&quot;&gt;목적&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;이 문서는 Linux환경에서 Process background에서 실행하는 방법에 대해 정리하기 위해 작성했다. &lt;/p&gt;

&lt;h1 id=&quot;linux환경에서-process-background에서-실행하는-방법&quot;&gt;Linux환경에서 Process background에서 실행하는 방법&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Linux 환경에서 터미널을 이용해 특정 작업을 실행할 경우 Foreground, Background로 Process를 실행할 수 있다. Foreground로 실행할 경우에는 중간에 터미널을 종료하게 되면 실행한 Process도 같이 종료하게 된다. &lt;/p&gt;

&lt;p&gt;터미널을 종료할 경우에도 Process가 계속 실행되게 하고 싶다면 Process를 Background 방식으로 실행해야 되며 실행하는 명령어는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;your_command &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;명령어 입력할 시 응답 예시는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1] 27255
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;linux환경에서background로-실행되고-있는특정-process를-확인하는-방법&quot;&gt;Linux환경에서 background로 실행되고 있는 특정 Process를 확인하는 방법&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;다음과 같은 명령어로 Linux환경에서 background로 실행되고 있는 특정 Process를 확인할 수 있다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ps -ef | grep &quot;your process name&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;명령어 입력할 시 응답 예시는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;501 26652     1   0 12:00PM ttys001    0:00.27 /Users/st/test/celery_chord_test/.venv/bin/python3.7 /Users/st/test/celery_chord_test/.venv/bin/celery -A celery_scheduler beat --loglevel=debug -f logs/celery_beat.log
501 27255 15184   0 12:01PM ttys001    0:00.45 /Users/st/test/celery_chord_test/.venv/bin/python3.7 /Users/st/test/celery_chord_test/.venv/bin/celery -A celery_worker worker --loglevel=debug --queues=test_model_build_q --concurrency=3 -f logs/celery_worker.log
501 27270 27255   0 12:01PM ttys001    0:00.04 /Users/st/test/celery_chord_test/.venv/bin/python3.7 /Users/st/test/celery_chord_test/.venv/bin/celery -A celery_worker worker --loglevel=debug --queues=test_model_build_q --concurrency=3 -f logs/celery_worker.log
501 27271 27255   0 12:01PM ttys001    0:00.01 /Users/st/test/celery_chord_test/.venv/bin/python3.7 /Users/st/test/celery_chord_test/.venv/bin/celery -A celery_worker worker --loglevel=debug --queues=test_model_build_q --concurrency=3 -f logs/celery_worker.log
501 27272 27255   0 12:01PM ttys001    0:00.04 /Users/st/test/celery_chord_test/.venv/bin/python3.7 /Users/st/test/celery_chord_test/.venv/bin/celery -A celery_worker worker --loglevel=debug --queues=test_model_build_q --concurrency=3 -f logs/celery_worker.log
501 27408 15184   0 12:01PM ttys001    0:00.00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn celery
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;linux환경에서background로-실행되고-있는특정-process를-종료하는-방법&quot;&gt;Linux환경에서 background로 실행되고 있는 특정 Process를 종료하는 방법&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;다음과 같은 명령어로 Linux환경에서 background로 실행되고 있는 특정 Process를 종료할 수 있다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pkill -9 -f &quot;celery&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;명령어 입력시 응답이 아무것도 안나오는 경우가 있다.  &lt;/p&gt;

&lt;p&gt;제대로 종료됬는 지 확인하고 싶다면 위에 설명한 grep 명령어를 이용해 확인하도록 한다. &lt;/p&gt;

&lt;h1 id=&quot;참고-자료&quot;&gt;참고 자료&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;참고 자료는 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://linuxhandbook.com/run-process-background/&quot;&gt;https://linuxhandbook.com/run-process-background/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="Linux" /><summary type="html">이 문서는 Linux환경에서 Process background에서 실행하는 방법에 대해 정리하기 위해 작성했다.</summary></entry><entry><title type="html">Kafka 설치 및 간단 사용법</title><link href="http://localhost:4000/kafka/kafka_quick_start_guide/" rel="alternate" type="text/html" title="Kafka 설치 및 간단 사용법" /><published>2020-02-21T00:00:00+09:00</published><updated>2020-02-21T00:00:00+09:00</updated><id>http://localhost:4000/kafka/kafka_quick_start_guide</id><content type="html" xml:base="http://localhost:4000/kafka/kafka_quick_start_guide/">&lt;h1 id=&quot;목적&quot;&gt;목적&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;이 글의 목적은 &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Apache Kafka&lt;/a&gt; 공식 사이트의 &lt;a href=&quot;https://kafka.apache.org/quickstart&quot;&gt;Quick start&lt;/a&gt; 를 따라하면서 학습했던 부분을 정리하고 공유하기 위해 작성했다.&lt;/p&gt;

&lt;p&gt;이 이문서에서는 Quick start에 포함된 가장 간단한 부분에 대하여 직접 실행한 내용만 포함되어 있으며, &lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Apache Kafka&lt;/a&gt;에 대한 자세한 내용은 공식 사이트 문서를 참고하도록 한다.&lt;/p&gt;

&lt;h1 id=&quot;설치&quot;&gt;설치&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;설치를 하기 위해 &lt;a href=&quot;https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.0/kafka_2.12-2.4.0.tgz&quot;&gt;링크&lt;/a&gt;에서 2.4.0 버전의 kafka를 다운받는다. 다운받고 해당 폴더에서 다음 명령어를 입력한다. &lt;/p&gt;

&lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xzf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafka_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tgz&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafka_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;서버-시작하기&quot;&gt;서버 시작하기 &lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Kafka는 ZooKeeper를 사용하고 있다. 그래서 먼저 ZooKeeper server를 실행한다. 편리한 실행을 위해 아래의 스크립트를 이용해 Kafka패키지에 포함되어 있는 ZooKeeper instance를 실행한다. 그 뒤에 Kakfa server를 실행한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bin/zookeeper-server-start.sh config/zookeeper.properties

$ bin/kafka-server-start.sh config/server.properties


[2020-01-02 21:47:03,844] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-02 21:47:03,847] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-02 21:47:03,851] INFO clientPortAddress is 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;topic-생성하기&quot;&gt;Topic 생성하기&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Kafka는 Topic이라는 것을 기준으로 메시지를 publish, subscribe 하는 방식으로 사용한다.&lt;/p&gt;

&lt;p&gt;테스트를 위해 “test”라는 이름의 Topic을 직접 생성해보자. 생성 시 설정은 1개의 단일 Partition과 1개의 Replica이다. 다음 명령어를 입력한다. 명령어 입력 후 &amp;gt; 모양이 터미널에 뜨며 메시지를 입력할 수 있다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;생성 후 다음과 같은 명령어를 입력해 정상적으로 Topic이 생성됬는지 확인할 수 있다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bin/kafka-topics.sh --list --bootstrap-server localhost:9092
test
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;테스트-메시지-보내기&quot;&gt;테스트 메시지 보내기&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Kafka는 터미널에서 파일에 입력하기, 표준 입력, 직접 전달의 방법으로 Kafka cluster에 메시지를 보낼 수 있다. &lt;/p&gt;

&lt;p&gt;다음과 같은 명령어를 입력 후 전달하고자 하는 메시지를 입력한다. 기본 적으로 각각의 라인이 하나의 독립된 메시지로 처리된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
test 1
test 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;consumer-실행하기&quot;&gt;Consumer 실행하기 &lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Kafka는 터미널에서 command line Consumer를 실행할 수 있으며 직접 터미널에서 특정 Topic으로 전달된 메시지를 볼 수 있다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
test 1
test 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;“테스트 메시지 보내기”에서 입력했던 터미널과 Consumer를 입력했던 터미널을 두 개의 터미널에서 각 각 띄우면 근실시간에 가깝게 입력된 메시지가 Consumer를 실행한 터미널에서 출력됨을 확인할 수 있다.&lt;/p&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="Kafka" /><summary type="html">이 글의 목적은 Apache Kafka 공식 사이트의 Quick start를 따라하면서 학습했던 부분을 정리하고 공유하기 위해 작성했다.</summary></entry><entry><title type="html">Celery를 활용한 ML 모델 빌드, 모델 정확성 평가, 배포</title><link href="http://localhost:4000/celery/celery_ml_model_build/" rel="alternate" type="text/html" title="Celery를 활용한 ML 모델 빌드, 모델 정확성 평가, 배포" /><published>2020-02-20T00:00:00+09:00</published><updated>2020-02-20T00:00:00+09:00</updated><id>http://localhost:4000/celery/celery_ml_model_build</id><content type="html" xml:base="http://localhost:4000/celery/celery_ml_model_build/">&lt;h1 id=&quot;목적&quot;&gt;목적&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;이 글은 ML 모델 기반의 API서비스를 만든 후, 추가적으로 고도화에 대해 공부하고 개발한 부분을 남기고 공유하기 위해 작성했다. &lt;/p&gt;

&lt;p&gt;이 문서는 Celery에 대해 기본적인 지식이 있다는 가정하에 문서가 진행된다. &lt;a href=&quot;https://docs.celeryproject.org/en/latest/index.html&quot;&gt;Celery&lt;/a&gt;를 모를 경우 링크를 참고한다. &lt;/p&gt;

&lt;h1 id=&quot;개발-환경&quot;&gt;개발 환경&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;테스트 환경은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Mac OS: Catalina 10.15.3&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Python 3.7&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Celery 4.4.0&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;개발-진행-목적&quot;&gt;개발 진행 목적&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;개발 진행 목적은 다음과 같은 기능을 가장 간단한 모델로 개발해 추후 ML 모델 빌드 기능의 고도화를 할 경우 참고할 수 있도록 개발해보는 것이다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Celery를 이용해 각기 다른 3가지 알고리즘이 적용된 ML 모델을 병렬로 3개 빌드한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;3개 빌드된 모델에 대한 정확성을 평가 후 제일 높은 정확성을 가진 ML 모델을 서비스에 적용한다. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;적용된 모델에 대해 슬랙으로 리포팅을 받는다. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;개발-셋팅-과정&quot;&gt;개발 셋팅 과정&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;모델 빌드의 트리거는 Celery 스케줄러를 이용해 진행한다. &lt;/p&gt;

&lt;p&gt;Celery 스케줄러를 만들기 위해 프로젝트 폴더에 celery_scheduler.py 파일을 만들고 다음과 같이 입력한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from celery import Celery
from celery.schedules import crontab
import os
from dotenv import load_dotenv
from os.path import join, dirname

# env setting
try:
    if os.path.isfile('.env') == True:
        dotenv_path = join(dirname(__file__), '.env')
        load_dotenv(dotenv_path)
except Exception as e:
    print(e)

CRON_JOB_TIME_HOUR = int(os.getenv(&quot;CRON_JOB_TIME_HOUR&quot;, &quot;5&quot;))
CRON_JOB_TIME_MINUTE = int(os.getenv(&quot;CRON_JOB_TIME_MINUTE&quot;, &quot;0&quot;))
ENV_NAME = str(os.getenv(&quot;ENV_NAME&quot;))
REDIS_URL = str(os.getenv(&quot;REDIS_URL&quot;))

print(&quot;----------------------&quot;)
print(&quot;CRON_JOB_TIME_HOUR : {}, CRON_JOB_TIME_MINUTE: {}&quot;.format(CRON_JOB_TIME_HOUR, CRON_JOB_TIME_MINUTE))
print(&quot;ENV_NAME : {}&quot;.format(ENV_NAME))
print(&quot;REDIS_URL : {}&quot;.format(REDIS_URL))
print(&quot;----------------------&quot;)

if ENV_NAME == &quot;test&quot;:
    app = Celery('celery_test', backend='redis://localhost', broker='redis://localhost')
else:    
    app = Celery('celery_test', backend=REDIS_URL, broker=REDIS_URL)

app.conf.timezone = 'Asia/Seoul'

# Set the beat scheduler.
app.conf.beat_schedule = {
    'test_models': {
        'task': 'task_ml_first.make_ml_model_build_job',
        'schedule': crontab(hour=CRON_JOB_TIME_HOUR, minute=CRON_JOB_TIME_MINUTE),
        'options' : { &quot;queue&quot;: &quot;test_model_build_q&quot; },
    }
}

if __name__ == &quot;__main__&quot;:
    print(&quot;start as main&quot;)
    app.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Celery 스케줄러가 스케줄링 잡을 Broker에 등록하면 Worker가 직접 태스크를 받아 처리해준다. Worker를 만들기 위해 celery_worker.py 파일을 만들고 아래와 같이 파일의 내용을 입력한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from celery import Celery
from dotenv import load_dotenv
from os.path import join, dirname
import os

# env setting
if os.path.isfile('.env') == True:
    dotenv_path = join(dirname(__file__), '.env')
    load_dotenv(dotenv_path)

CRON_JOB_TIME_HOUR = int(os.getenv(&quot;CRON_JOB_TIME_HOUR&quot;, &quot;5&quot;))
CRON_JOB_TIME_MINUTE = int(os.getenv(&quot;CRON_JOB_TIME_MINUTE&quot;, &quot;0&quot;))
ENV_NAME = str(os.getenv(&quot;ENV_NAME&quot;))
REDIS_URL = str(os.getenv(&quot;REDIS_URL&quot;))

# set celery work
if ENV_NAME == &quot;test&quot;:
    app = Celery(&quot;celery_worker&quot;,
                        backend=&quot;redis://localhost&quot;,
                        broker=&quot;redis://localhost&quot;,
                        include=[&quot;task_ml_first&quot;])
else:
    app = Celery(&quot;celery_worker&quot;,
                        backend=REDIS_URL,
                        broker=REDIS_URL,
                        include=[&quot;task_ml_first&quot;])

# task routing config test
app.conf.update = {
    'generate_models': {
        'task': 'task_ml_first.complete_message_print_model_build',
        'options' : { &quot;queue&quot;: &quot;test_model_build_q&quot; },
    },
}

app.conf.timezone = &quot;Asia/Seoul&quot;

if __name__ == &quot;__main__&quot;:
    app.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Worker가 실제 어떤 작업을 실행하는 지 정의하기 위한 task_ml_first.py 파일을 만들고 내용을 다음과 같이 입력한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import os
import time
from datetime import datetime
from celery_worker import app
from celery import group, chord
from os.path import join, dirname
from dotenv import load_dotenv
import random
from slack_fucntion import send_message_to_slack

if os.path.isfile('./.env') == True:
    dotenv_path = join(dirname(__file__), '.env')
    load_dotenv(dotenv_path)

ENV_NAME = str(os.getenv(&quot;ENV_NAME&quot;))


def deploy_model(model_name):
    print(&quot;{} is deploy&quot;.format(model_name))
    send_message_to_slack({&quot;text&quot;:&quot;{} is deployed&quot;.format(model_name)})



@app.task(name='task_ml_first.build_ml_models')
def build_ml_models(results):
    print(&quot;{} test model build&quot;.format(results))
    max_num = 0

    for result in results:
        if max_num &amp;lt; result['value']:
            max_num = result['value']
    
    print(max_num)

    for result in results:
        if max_num == result['value']:
            model_name = result['model_name']
        
    deploy_model(model_name)

    return True


@app.task(name='task_ml_first.first_method_ml_model_build')
def first_method_ml_model_build():
    random_number = random.randrange(1,10)

    print(&quot;first_method_ml_model_build() start!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;)
    time.sleep(random_number)
    print(&quot;first_method_ml_model_build() end!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;)

    return {&quot;model_name&quot; : &quot;first_method_ml_model_build&quot;, &quot;value&quot;: random_number}


@app.task(name='task_ml_first.second_method_ml_model_build')
def second_method_ml_model_build():
    random_number = random.randrange(1,10)

    print(&quot;second_method_ml_model_build() start!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;)
    time.sleep(random_number)
    print(&quot;second_method_ml_model_build() end!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;)

    return {&quot;model_name&quot; : &quot;second_method_ml_model_build&quot;, &quot;value&quot;: random_number}


@app.task(name='task_ml_first.third_method_ml_model_build')
def third_method_ml_model_build():
    random_number = random.randrange(1,10)

    print(&quot;third_method_ml_model_build() start!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;)
    time.sleep(random_number)
    print(&quot;third_method_ml_model_build() end!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&quot;)

    return {&quot;model_name&quot; : &quot;third_method_ml_model_build&quot;, &quot;value&quot;: random_number}


@app.task(name='task_ml_first.make_ml_model_build_job')
def make_ml_model_build_job():
    task_signature_list = []
    
    try:
        print(&quot;make_ml_model_build_job executed&quot;)
        
        task_signature_list.append(first_method_ml_model_build.signature())
        task_signature_list.append(second_method_ml_model_build.signature())
        task_signature_list.append(third_method_ml_model_build.signature())

        model_build_work_chord = chord(task_signature_list, build_ml_models.s())
        model_build_work_chord.apply_async(queue=&quot;test_model_build_q&quot;)  # queue 지정
        print(&quot;make_ml_model_build_job.apply_async() called&quot;)
    except Exception as e:
        print(e)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;슬랙 메시지를 보내기 위해 slack_fucntion.py 파일을 만들고 미리 작성한 코드를 아래와 같이 입력한다. webhook_url은 미리 각자 생성한 url를 입력하면 된다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import json
import requests
import os


def send_message_to_slack_channel_using_slack_api(message, webhook_url):
    response = requests.post(
            webhook_url, data=json.dumps(message),
            headers={'Content-Type': 'application/json'}
    )
    
    return response


def send_message_to_slack(message):
    webhook_url = &quot;&quot;
    response = send_message_to_slack_channel_using_slack_api(message, webhook_url)

    if response.text != 'ok':
        print('error_function_name', 'send_message_to_slack')
        print('error_message', response.text)
        raise Exception
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;celery-실행-명령&quot;&gt;Celery 실행 명령&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Celery 스케줄러 실행 명령은 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ celery -A celery_scheduler beat --loglevel=debug
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Celery worker 실행 명령은 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ celery -A celery_worker worker --loglevel=debug --queues=test_model_build_q --concurrency=3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;결과&quot;&gt;결과&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;결과는 미리 설정된 스케줄링 시간에 다음과 같은 형태의 메시지가 슬랙에 온다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{}_method_ml_model_build is deployed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이로써 Celery를 활용해 가장 정확도가 높은 모델을 서비스에 적용하고 슬랙으로 알림 받는 기능을 가장 간단한 형태로 개발을 완료했다. 추후 프로덕션 개발 시 참고해 진행하면 될 것 같다.&lt;/p&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="Celery" /><summary type="html">이 글은 ML 모델 기반의 API서비스를 만든 후, 추가적으로 고도화에 대해 공부하고 개발한 부분을 남기고 공유하기 위해 작성했다. </summary></entry><entry><title type="html">Elasticsearch multi_match 기본 사용법 및 Type에 대한 설명 정리</title><link href="http://localhost:4000/elasticsearch/elasticsearch_multi_match/" rel="alternate" type="text/html" title="Elasticsearch multi_match 기본 사용법 및 Type에 대한 설명 정리" /><published>2020-02-10T00:00:00+09:00</published><updated>2020-02-10T00:00:00+09:00</updated><id>http://localhost:4000/elasticsearch/elasticsearch_multi_match</id><content type="html" xml:base="http://localhost:4000/elasticsearch/elasticsearch_multi_match/">&lt;h1 id=&quot;문서-목적&quot;&gt;문서 목적&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;이 문서는 Elasticsearch에서 Multi_match query를 사용할 경우 필요한 지식에 대해 정리하고 공유하기 위해 작성했다. 가독성을 위해 Elasticsearch는 ES로 표기한다. &lt;/p&gt;

&lt;h1 id=&quot;테스트-환경&quot;&gt;테스트 환경&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;테스트 환경은 다음과 같다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ES, Kibana: 7.1 &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MacOS Catalina 10.15.2&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;multi_match-기본-설정에-대한-설명&quot;&gt;Multi_match 기본 설정에 대한 설명&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;아래와 같이 Query를 실행할 경우 기본값으로 설정되는 항목에 대해 설명한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;query&quot;: {
        &quot;multi_match&quot; : {
            &quot;query&quot;:    &quot;this is a test&quot;,
            &quot;fields&quot;: [ &quot;subject&quot;, &quot;message&quot; ]
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;기본값으로 설정되는 항목은 다음과 같다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Query 대상 필드 개수 제한: 1024개. &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/7.x/search-settings.html&quot;&gt;참고문서&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Type: Best_fields&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;multi_match-wildcards-가중치-설명&quot;&gt;Multi_match wildcards, 가중치 설명&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Multi_match는 Wildcards를 지원한다. 다음은 예시이다. 예시에서는 “*_name”로 Field를 지정해 _name으로 끝나는 Field를 대상 Field로 지정한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot; : {
      &quot;query&quot;:    &quot;Will Smith&quot;,
      &quot;fields&quot;: [ &quot;title&quot;, &quot;*_name&quot; ] 
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;또한, 각 각의 Field에 대해 가중치를 부여할 수 있다. 다음은 예시이다. 예시에서는 “subject” field는 “message” field에 대해 3배 중요하다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot; : {
      &quot;query&quot; : &quot;this is a test&quot;,
      &quot;fields&quot; : [ &quot;subject^3&quot;, &quot;message&quot; ] 
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;multi_match-type-option에-대한-설명&quot;&gt;Multi_match Type option에 대한 설명&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;다음은 Multi_match type과 해당 Type에 대한 설명을 표로 정리한 것이다. &lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;best_fields&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;(&lt;strong&gt;기본 설정값&lt;/strong&gt;) 모든 Field에 대해 Match되는 Field를 찾는다. 가장 잘 Match되는 &lt;strong&gt;1개의 Field를 기준으로 Score를 계산&lt;/strong&gt;한다. 참고문서 &lt;code class=&quot;highlighter-rouge&quot;&gt;best_fields&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;most_fields&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;모든 Field에 대해 Match되는 각 각의 field에 대해 점수를 계산하고 모두 합한다. 합한 점수를 field 개수로 나눠서 최종 스코어를 계산한다. 참고문서 &lt;code class=&quot;highlighter-rouge&quot;&gt;most_fields&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cross_fields&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Treats fields with the same &lt;code class=&quot;highlighter-rouge&quot;&gt;analyzer&lt;/code&gt; as though they were one big field. Looks for each word in &lt;strong&gt;any&lt;/strong&gt;field. See &lt;code class=&quot;highlighter-rouge&quot;&gt;cross_fields&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;phrase&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Runs a &lt;code class=&quot;highlighter-rouge&quot;&gt;match_phrase&lt;/code&gt; query on each field and uses the &lt;code class=&quot;highlighter-rouge&quot;&gt;_score&lt;/code&gt; from the best field. See &lt;code class=&quot;highlighter-rouge&quot;&gt;phrase&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;phrase_prefix&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;phrase_prefix&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Runs a &lt;code class=&quot;highlighter-rouge&quot;&gt;match_phrase_prefix&lt;/code&gt; query on each field and uses the &lt;code class=&quot;highlighter-rouge&quot;&gt;_score&lt;/code&gt; from the best field. See &lt;code class=&quot;highlighter-rouge&quot;&gt;phrase&lt;/code&gt;and &lt;code class=&quot;highlighter-rouge&quot;&gt;phrase_prefix&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bool_prefix&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;Creates a &lt;code class=&quot;highlighter-rouge&quot;&gt;match_bool_prefix&lt;/code&gt; query on each field and combines the &lt;code class=&quot;highlighter-rouge&quot;&gt;_score&lt;/code&gt;from each field. See &lt;code class=&quot;highlighter-rouge&quot;&gt;bool_prefix&lt;/code&gt;.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;best_fields-type&quot;&gt;Best_fields type&lt;/h2&gt;

&lt;p&gt;Best_fields type은 &lt;strong&gt;기본 설정값&lt;/strong&gt;이며 모든 Field에 대해 Match되는 Field를 찾는다. Best_fields type는 dis_max query를 여러 개의 field에 대해 각 각 Match query한 결과와 같다.&lt;/p&gt;

&lt;p&gt;예시는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot; : {
      &quot;query&quot;:      &quot;brown fox&quot;,
      &quot;type&quot;:       &quot;best_fields&quot;,
      &quot;fields&quot;:     [ &quot;subject&quot;, &quot;message&quot; ],
      &quot;tie_breaker&quot;: 0.3
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 예시 Query는 다음과 같이 실행될 것이다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;dis_max&quot;: {
      &quot;queries&quot;: [
        { &quot;match&quot;: { &quot;subject&quot;: &quot;brown fox&quot; }},
        { &quot;match&quot;: { &quot;message&quot;: &quot;brown fox&quot; }}
      ],
      &quot;tie_breaker&quot;: 0.3
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Best_fields type은 가장 잘 Match되는 &lt;strong&gt;1개의 Field를 기준으로 Score를 계산&lt;/strong&gt;한다. tie_breaker 설정 시 다음과 같이 점수가 계산된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;가장 잘 Match되는 &lt;strong&gt;1개의 Field를 기준으로 Score를 계산&lt;/strong&gt;한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;나머지 Field에 대해 tie_breaker * score를 한 후 Score에 Plus한다. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;참고&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Best_fields Type Query 시 “tie_breaker”를 1로 설정하면, Most_fields Type으로 “tie_braker”를 설정 하지 않았을 경우와 같은 Score가 나오게 된다.&lt;/p&gt;

&lt;p&gt;이 이유는 점수 계산 방식의 차이인데, Best_fields는 각 field의 Score 중 제일 큰 값을 최종 Score로 하는 반면에 Most_fields는 각 field의 Score를 모두 더해서 최종 Score를 계산하기 때문이다.&lt;/p&gt;

&lt;p&gt;따라서, Best_fields Type의 “tie_braker”를 1로 설정할 경우 모든 Field의 Score를 합해 최종 Score를 계산하게 되므로 Most_fields Type과 동일한 점수가 나오게 된다.&lt;/p&gt;

&lt;p&gt;점수 계산에 대해 조금 더 자세히 설명하자면, Best_fields type은 각 각의 Field에 대해 Field별로 &lt;a href=&quot;https://ict-nroo.tistory.com/82&quot;&gt;BM25&lt;/a&gt;의 알고리즘을 이용해 점수를 계산한다. &lt;/p&gt;

&lt;p&gt;즉, 주어진 대상 Field 별로 Score를 계산하고 이 계산된 모든 Score를 비교해 가장 큰 값을 최종 Document의 Score로 결정하는 것이다. 다음은 예시이다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &quot;hits&quot; : {
    &quot;total&quot; : {
      &quot;value&quot; : 4,
      &quot;relation&quot; : &quot;eq&quot;
    },
    &quot;max_score&quot; : 0.9913396,
    &quot;hits&quot; : [
      {
        &quot;_shard&quot; : &quot;[test_multi_match_query][0]&quot;,
        &quot;_node&quot; : &quot;_MqXQL7fShunzdcE4D6j9w&quot;,
        &quot;_index&quot; : &quot;test_multi_match_query&quot;,
        &quot;_type&quot; : &quot;_doc&quot;,
        &quot;_id&quot; : &quot;QfQRHnABGReuIwC7G8rY&quot;,
        &quot;_score&quot; : 0.9913396,
        &quot;_source&quot; : {
          &quot;first_field&quot; : &quot;first&quot;,
          &quot;second_field&quot; : &quot;first&quot;,
          &quot;third_field&quot; : &quot;first&quot;
        },
        &quot;_explanation&quot; : {
          &quot;value&quot; : 0.9913396,
          &quot;description&quot; : &quot;max of:&quot;,
          &quot;details&quot; : [
            {
              &quot;value&quot; : 0.6103343,
              &quot;description&quot; : &quot;weight(second_field:first in 1) [PerFieldSimilarity], result of:&quot;,
              &quot;details&quot; : {...}
            },
            {
              &quot;value&quot; : 0.30873197,
              &quot;description&quot; : &quot;weight(first_field:first in 1) [PerFieldSimilarity], result of:&quot;,
              &quot;details&quot; : {...}
            },
            {
              &quot;value&quot; : 0.9913396,
              &quot;description&quot; : &quot;weight(third_field:first in 1) [PerFieldSimilarity], result of:&quot;,
              &quot;details&quot; : {...}
            }
          ]
        }
      },
...하략
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 예시는 Multi_match query를 Best_fields type으로 3개의 Field에 대해 Query 했을 때 계산 과정을 설명한 내용이다. 이 Multi_match query의 Query절은 3개의 Field에 대해 정확히 일치한다. (Ex. 검색어: First, 대상 필드 3개의 값: First)&lt;/p&gt;

&lt;p&gt;예시 중 중요한 부분은 “hits” → ”hits” → ”_explanation” -&amp;gt; “details” 부분이다. 해당 부분을 보면 각 각의 3개의 Field에 대해 Per field 별로 Score를 계산하고 그 중 최고점을 최종 Score로 계산한다. 모두 Query 절이 정확히 일치해도 모든 문서의 대상 Field가 얼마나 자주 등장하는 지, Term의 길이 등 Relevance 계산 알고리즘에 의해 점수가 다르게 계산된다. &lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;공식 문서는 best_fields를 참고한다. &lt;/code&gt;&lt;/p&gt;

&lt;p&gt;중요 Operator and minimum_should_match에 대한 설명&lt;/p&gt;

&lt;p&gt;Best_fields type, most_fields type은 공통적으로 Field 중심적이다. 이 두 개의 Type은 각 각의 Field에 대해 Match query를 실행하며 Match query마다 Operator와 Minimum_should_match가 적용된다. &lt;/p&gt;

&lt;p&gt;예시는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot; : {
      &quot;query&quot;:      &quot;Will Smith&quot;,
      &quot;type&quot;:       &quot;best_fields&quot;,
      &quot;fields&quot;:     [ &quot;first_name&quot;, &quot;last_name&quot; ],
      &quot;operator&quot;:   &quot;and&quot; 
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 Query는 Will, Smith로 분석된 Token이 First_name, Last_name 중에 1개의 field라도 모두 존재하면 Match된다. 식으로 표현하면 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(+first_name:will +first_name:smith) 
| (+last_name:will  +last_name:smith)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정리하면, Query를 분석한 Terms가 1개의 Field에 대해 모두 존재할 경우 Match된다. &lt;/p&gt;

&lt;h2 id=&quot;most_fields-type&quot;&gt;Most_fields type&lt;/h2&gt;

&lt;p&gt;모든 Field에 대해 Match되는 각 각의 field에 대해 점수를 계산하고 모두 합한다. &lt;/p&gt;

&lt;p&gt;다음은 예시이다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot; : {
      &quot;query&quot;:      &quot;quick brown fox&quot;,
      &quot;type&quot;:       &quot;most_fields&quot;,
      &quot;fields&quot;:     [ &quot;title&quot;, &quot;title.original&quot;, &quot;title.shingles&quot; ]
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같이 작성된 쿼리는 실제로 다음과 같은 쿼리로 실행될 것이다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;should&quot;: [
        { &quot;match&quot;: { &quot;title&quot;:          &quot;quick brown fox&quot; }},
        { &quot;match&quot;: { &quot;title.original&quot;: &quot;quick brown fox&quot; }},
        { &quot;match&quot;: { &quot;title.shingles&quot;: &quot;quick brown fox&quot; }}
      ]
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 예시는 Title이라는 이름의 field를 다른 분석기를 통해 분석된 결과에 Match 되는 지 확인하고 점수를 계산하기 때문에 위 예시 Query의 검색 키워드인 “quick brown fox”에 더 근접한 결과를 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;점수 계산 방법은 다음과 같다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;각 각의 Match되는 field에 대해 점수를 계산한 후 합한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;자세한 사항은 &lt;code class=&quot;highlighter-rouge&quot;&gt;most_fields를 참고한다.&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;phrase-and-phrase_prefix-type&quot;&gt;Phrase and Phrase_prefix type&lt;/h2&gt;

&lt;p&gt;phrase, Phrase_prfix type은 Best_fields type과 비슷하게 동작한다. 다른 점은 Match query 대신 Match_phrase, Match_phrase_prefix으로 동작한다는 것이다. &lt;/p&gt;

&lt;p&gt;자세한 사항은 &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-dsl-multi-match-query.html#type-phrase&quot;&gt;Phrase, Phrase_prefix&lt;/a&gt;를 참고한다. &lt;/p&gt;

&lt;h2 id=&quot;cross_fields-type&quot;&gt;Cross_fields type&lt;/h2&gt;

&lt;p&gt;Cross_fields type은 여러 field가 일치해야 하는 구조화된 문서에 특히 유용하다. 예를 들어, “Will Smith” 키워드로 First_name과 Last_name에 대해 Query할 경우, 최적의 Match는 1개 Field에 “Will”, 나머지 1개의 Field가 “Smith”에 Match될 경우일 것이다. &lt;/p&gt;

&lt;p&gt;Cross_fields type은 다음과 같이 검색을 진행한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Query를 분석기로 분석한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;분석된 각 각의 Term들을 모든 Field에 대해 질의하는데, 이 질의 대상이 되는 Field들을 1개의 큰 Field로 만들어 Match 되는 지 질의한다. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;중요 Most_field type 차이점 비교&lt;/p&gt;

&lt;p&gt;Most_field type과의 차이점을 비교하면 2가지가 있다. &lt;/p&gt;

&lt;p&gt;첫 번째는 Most_field type은 field마다 Operator, minimum_should_match를 적용하지만 Cross_fields type은 Term마다 적용한다.&lt;/p&gt;

&lt;p&gt;두 번째는 관련성이다. 만약 “Will Smith”이라는 이름을 검색한다고 생각해보자. 검색 시 ‘Will’, ‘Smith’이라는 두개의 Terms는 각 각의 last_name, first_name Field에 대해 검색할 것이다. 결과는 ”Smith Jones”가 “Will Smith” 보다 점수가 높을 것이다.&lt;/p&gt;

&lt;p&gt;왜냐하면, last_name에 “Smith”는 굉장히 흔하지 않기 때문에 Last_name: “Smith”의 Score는 Last_name: “Will”, First_name: “Smith”의 총합 Score보다 더 높기 때문이다.&lt;/p&gt;

&lt;p&gt;Cross_fields type은 query로 입력한 키워드를 분석한 후 모든 Field에 대해 각 각의 Term을 검색한다. 예시는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GET /_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot; : {
      &quot;query&quot;:      &quot;Will Smith&quot;,
      &quot;type&quot;:       &quot;cross_fields&quot;,
      &quot;fields&quot;:     [ &quot;first_name&quot;, &quot;last_name&quot; ],
      &quot;operator&quot;:   &quot;and&quot;
    }
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 Query는 다음과 같이 실행될 것이다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+(first_name:will last_name:will) 
+(first_name:smith last_name:smith)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;따라서, 최소한 1개 이상의 Field에 대해 모두 Terms가 존재할 것이다.&lt;/p&gt;

&lt;h1 id=&quot;참고-자료&quot;&gt;참고 자료 &lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;참고 자료는 다음과 같다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ES 공식문서: &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-dsl-multi-match-query.html&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/7.x/query-dsl-multi-match-query.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ES multi_match query field 개수 설정 관련 공식 문서: &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/7.x/search-settings.html&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/7.x/search-settings.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="Elasticsearch" /><summary type="html">이 문서는 Elasticsearch에서 Multi match query를 사용할 경우 필요한 지식에 대해 정리하고 공유하기 위해 작성했다.</summary></entry><entry><title type="html">Crontab 기본적인 사용법 정리</title><link href="http://localhost:4000/crontab/cron_tab_basic/" rel="alternate" type="text/html" title="Crontab 기본적인 사용법 정리" /><published>2020-02-10T00:00:00+09:00</published><updated>2020-02-10T00:00:00+09:00</updated><id>http://localhost:4000/crontab/cron_tab_basic</id><content type="html" xml:base="http://localhost:4000/crontab/cron_tab_basic/">&lt;h1 id=&quot;문서-목적&quot;&gt;문서 목적&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;이 문서는 Crontab에 대해 학습한 부분들을 정리하고 공유하기 위해 작성하였다.&lt;/p&gt;

&lt;h1 id=&quot;crontab-설명&quot;&gt;Crontab 설명&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Crobtab에 대한 설명하면 다음과 같다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;소프트웨어 유틸리티 Cron은 유닉스 계열 컴퓨터 운영 체제의 시간 기반 잡 스케줄러이다. 소프트웨어 환경을 설정하고 관리하는 사람들은 작업을 고정된 시간, 날짜, 간격에 주기적으로 실행할 수 있도록 스케줄링하기 위해 Cron을 사용한다. (출처- &lt;a href=&quot;https://ko.wikipedia.org/wiki/Cron&quot;&gt;위키백과&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;crontab-기본적인-명령어&quot;&gt;Crontab 기본적인 명령어&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Contab에 등록된 작업을 보기 위해 다음과 같은 명령어를 입력한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ crontab -l

0 11 * * * /Users/st/test/mysql_to_mysql_shell_sciprt/etl.sh &amp;gt; /Users/st/test/mysql_to_mysql_shell_sciprt/logs.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Crontab에 작업을 등록하기 위해서 다음과 같은 명령어를 입력한다. 다음과 같은 명령어를 입력시 편집화면으로 진입하는데 이 화면에서 등록할 작업을 설정하면 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ crontab -e
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Crontab을 지우기 위해서는 다음과 같은 명령어를 입력하면 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ crontab -r
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;crontab-시간-등록-형식&quot;&gt;Crontab 시간 등록 형식&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Crontab의 시간 등록 형식은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;* * * * *  실행할 명령어
┬ ┬ ┬ ┬ ┬
│ │ │ │ │
│ │ │ │ │
│ │ │ │ └───────── 요일 (0 - 6) (0:일요일, 1:월요일, 2:화요일, …, 6:토요일)
│ │ │ └───────── 월 (1 - 12)
│ │ └───────── 일 (1 - 31)
│ └───────── 시 (0 - 23)
└───────── 분 (0 - 59)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;crontab-등록-예시&quot;&gt;Crontab 등록 예시&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Crontab에 1분마다 스크립트를 실행하는 작업을 등록하는 예시는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;* * * * * /root/every_1min.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Crontab에 10분마다 스크립트를 실행하는 작업을 등록하는 예시는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;*/10 * * * * /root/every_10min.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;나머지 예시는 다음 링크를 참조한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://zetawiki.com/wiki/%EB%A6%AC%EB%88%85%EC%8A%A4_%EB%B0%98%EB%B3%B5_%EC%98%88%EC%95%BD%EC%9E%91%EC%97%85_cron,_crond,_crontab&quot;&gt;https://zetawiki.com/wiki/리눅스_반복_예약작업_cron,_crond,_crontab&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;crontab-로깅하는-방법&quot;&gt;Crontab 로깅하는 방법&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Crontab에 등록된 작업이 실행된 기록을 남기고 싶다면 다음과 같이 Crontab에 작업을 등록하면 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0 11 * * * 실행할 명령어 &amp;gt; 로그를 남길 파일 이름
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;참고-자료&quot;&gt;참고 자료&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;다음은 참고한 자료의 이름과 링크이다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Crontab 설명 위키백과: &lt;a href=&quot;https://ko.wikipedia.org/wiki/Cron&quot;&gt;https://ko.wikipedia.org/wiki/Cron&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;리눅스 반복 예약작업 cron, crond, crontab: &lt;a href=&quot;https://zetawiki.com/wiki/%EB%A6%AC%EB%88%85%EC%8A%A4_%EB%B0%98%EB%B3%B5_%EC%98%88%EC%95%BD%EC%9E%91%EC%97%85_cron,_crond,_crontab&quot;&gt;https://zetawiki.com/wiki/리눅스_반복_예약작업_cron,_crond,_crontab&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;리눅스 크론탭(Linux Crontab) 사용법: &lt;a href=&quot;https://jdm.kr/blog/2&quot;&gt;https://jdm.kr/blog/2&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="Crontab" /><summary type="html">이 문서는 Crontab에 대해 학습한 부분들을 정리하고 공유하기 위해 작성하였다.</summary></entry><entry><title type="html">Shell script 기본 학습 정리</title><link href="http://localhost:4000/shell_script/shell_script_basic/" rel="alternate" type="text/html" title="Shell script 기본 학습 정리 " /><published>2020-02-10T00:00:00+09:00</published><updated>2020-02-10T00:00:00+09:00</updated><id>http://localhost:4000/shell_script/shell_script_basic</id><content type="html" xml:base="http://localhost:4000/shell_script/shell_script_basic/">&lt;h1 id=&quot;문서-목적&quot;&gt;문서 목적&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;이 문서는 Bash shell sciprt에 대해 학습한 부분들을 정리하고 공유하기 위해 작성하였다. 이 문서는 Bash schell script를 기준으로 작성하였다. &lt;/p&gt;

&lt;p&gt;프로그래밍에 대한 기초적인 지식이 있다는 가정하에 문서를 작성했다. 해당 지식이 없을 경우 해당 지식을 미리 학습하고 문서를 읽을 것을 권장한다. &lt;/p&gt;

&lt;h1 id=&quot;터미널에-string-출력하기&quot;&gt;터미널에 String 출력하기&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;shell script에서 터미널에 String을 출력하는 방법은 echo, printf 명령어를 이용한 2가지의 방법이 있다. echo 명령을 이용할 시 출력될 때 자동으로 줄바꿈이 된다.&lt;/p&gt;

&lt;p&gt;test_script.sh를 만들고 다음과 같이 생성된 파일에 내용을 입력한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;i love Mac!&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;printf&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;i love Mac!&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Shell script를 실행하는 방법은 다음과 같이 3가지 방법이 있으며 문서의 가독성을 위해 실행하는 방법은 더이상 기술하지 않는다. 3가지 방법 중 적절한 것을 선택해 실행하도록 한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bash test_script.sh

$ sh test_script.sh

$ chmod +x test_script.sh 
$ ./test_script.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실행 시 결과는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;i love Mac!
i love Mac!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;예시의 Shell script의 내용 중 “#!/bin/bash”의 의미는 다음과 같다. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;#!: 매직넘버, 파일의 가장 처음에 위치하고 있으며 스크립트를 실행할 프로그램을 지정할 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;따라서 “#!/bin/bash”의 의미는 bash로 해당 스크립트를 실행하도록 지정하는 것이다. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;변수-종류-및-사용-방법&quot;&gt;변수 종류 및 사용 방법&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Shell script에서의 변수는 전역변수, 지역변수, 환경변수, 예약변수가 있다.&lt;/p&gt;

&lt;h2 id=&quot;전역-변수-지역-변수&quot;&gt;전역 변수, 지역 변수&lt;/h2&gt;

&lt;p&gt;먼저 전역변수와 지역변수를 설명하면, Shell script에서 선언된 변수는 기본적으로 전역 변수로 되며 지역변수는 함수 내에서 선언할 때에만 사용할 수 있으며 변수명 앞에 local를 붙여주면 된다.&lt;/p&gt;

&lt;p&gt;변수를 정의하는 방법은 “변수명=값”으로 할 수 있다. 선언 시 &lt;strong&gt;공백을 넣지 않도록 조심&lt;/strong&gt;한다. 변수를 사용할 때에는 “${변수명}”으로 하면 된다. &lt;/p&gt;

&lt;p&gt;전역 변수와 지역변수를 사용하기 위해 variables.sh를 만들고 다음과 같이 생성된 파일에 내용을 입력하고 실행한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 전역변수 선언&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hello world&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;

string_test&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
	&lt;span class=&quot;c&quot;&gt;# 지역변수 선언&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;local hello world&quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

string_test

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실행 결과는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hello world
local hello world
hello world
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과를 통해 지역 변수는 함수 내에서 선언을 할 경우 함수가 종료되는 것과 동시에 삭제된다는 것을 알 수 있다. &lt;/p&gt;

&lt;h2 id=&quot;환경-변수&quot;&gt;환경 변수&lt;/h2&gt;

&lt;p&gt;Shell script에서 환경 변수도 이용할 수 있는데 export 명령어를 이용해 사용 가능하다. &lt;/p&gt;

&lt;p&gt;테스트를 위해 기존 variables.sh의 내용을 다음과 같이 수정한다. 내용 중 ${PWD}는 예약변수이며 다음 카테고리에 있으니 환경 변수에 대한 것만 보고 넘어가도록 한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hello world&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;

string_test&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;local hello world&quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

string_test

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;hello_world&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hello world_export&quot;&lt;/span&gt;

bash &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PWD&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/export_test.sh

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;hello_world&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;export_test.sh를 만들고 다음과 같이 내용을 입력한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;hello_world&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;variables.sh를 실행한 결과는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hello world
local hello world
hello world
hello world_export
hello world_export
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래 2줄의 결과를 통해 variables.sh에서 export한 환경변수가 export_test.sh에서 출력된 것을 확인할 수 있다. &lt;/p&gt;

&lt;h2 id=&quot;예약-변수&quot;&gt;예약 변수&lt;/h2&gt;

&lt;p&gt;예약 변수는 Shell script에서 미리 정의된 변수이다. 사용 방법은 Shell script에서 ${예약변수명}으로 사용하면 된다.&lt;/p&gt;

&lt;p&gt;아래와 같은 예약 변수들이 있으며 더 많은 예약 변수들이 있지만 잦은 빈도로 사용하는 것 위주로 정리했다. 나머지 다른 예약변수는 &lt;a href=&quot;https://blog.gaerae.com/2015/01/bash-hello-world.html&quot;&gt;문서&lt;/a&gt;의 예약변수 카테고리를 참고한다. &lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;자&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;HOME&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;사용자의 홈 디렉토리&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PATH&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;실행 파일을 찾을 경로&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PWD&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;사용자의 현재 작업중인 디렉토리&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SECONDS&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;스크립트가 실행된 초 단위 시간&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SHELL&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;로그인해서 사용하는 쉘&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PPID&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;부모 프로세스의 PID&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BASH&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;BASH 실행 파일 경로&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BASH_ENV&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;스크립트 실행시 BASH 시작 파일을 읽을 위치 변수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BASH_VERSION&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;설치된 BASH 버전&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BASH_VERSINFO&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BASH_VERSINFO[0]&lt;/code&gt;~&lt;code class=&quot;highlighter-rouge&quot;&gt;BASH_VERSINFO[5]&lt;/code&gt;배열로 상세정보 제공&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OSTYPE&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;운영체제 종류&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;EUID&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;su&lt;/code&gt; 명령에서 사용하는 사용자의 유효 아이디 값(&lt;code class=&quot;highlighter-rouge&quot;&gt;UID&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;EUID&lt;/code&gt; 값은 다를 수 있음)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GROUPS&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;사용자 그룹(&lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/passwd&lt;/code&gt; 값을 출력)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PS1&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;기본 프롬프트 변수(기본값: &lt;code class=&quot;highlighter-rouge&quot;&gt;bash\$&lt;/code&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PS2&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;보조 프롬프트 변수(기본값: &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&lt;/code&gt;), 명령을 “\“를 사용하여 명령 행을 연장시 사용됨&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PS3&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;쉘 스크립트에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;select&lt;/code&gt; 사용시 프롬프트 변수(기본값: &lt;code class=&quot;highlighter-rouge&quot;&gt;#?&lt;/code&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;PS4&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;쉘 스크립트 디버깅 모드의 프롬프트 변수(기본값: &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TMOUT&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;0&lt;/code&gt;이면 제한이 없으며 &lt;code class=&quot;highlighter-rouge&quot;&gt;time&lt;/code&gt;시간 지정시 지정한 시간 이후 로그아웃&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;반복-실행문for-사용하기&quot;&gt;반복 실행문(for) 사용하기&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;반복 실행문 중 for 문은 다음과 같은 형태로 사용할 수 있다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for 변수 in list
do
	명령 
done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;test_for.sh 파일을 생성하고 아래의 내용을 입력한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;string &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hello&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;world&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;...&quot;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;do
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실행하고 결과를 확인한다. 실행 결과는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;hello
world
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;제어문-사용하기&quot;&gt;제어문 사용하기&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;제어문은 프로그램내의 문장 실행 순서를 제어하는 것이다. &lt;/p&gt;

&lt;p&gt;제어문은 선택적 실행문과 반복 실행문이 있다. 이 카테고리에서는 선택적 실행문 중 if문에 대해 설명한다. &lt;/p&gt;

&lt;p&gt;if문은 다음과 같은 형태로 사용할 수 있다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if 조건명령 
then
	명령
else
	명령
fi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;if.sh 파일을 만들고 다음과 같이 내용을 입력하고 실행한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3
&lt;span class=&quot;nv&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4

&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt; x &amp;lt; y &lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;x is less than y&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;y is less than x&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실행 결과는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3
4
x is less than y

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;if문은 다음과 같은 형태로 사용할 수 있다. &lt;/p&gt;

&lt;h1 id=&quot;함수&quot;&gt;함수&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;함수는 하나의 목적으로 사용되는 명령들의 집합이다. &lt;/p&gt;

&lt;p&gt;함수는 다음과 같은 형태로 사용할 수 있다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function 함수이름 
{
	명령들
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;funtion.sh 파일을 만들고 다음과 같이 내용을 입력하고 실행한다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
function_test&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi!&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;function &lt;/span&gt;abc&lt;span class=&quot;o&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;abc&quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

function_test
abc

abc &lt;span class=&quot;s2&quot;&gt;&quot;abb&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;para&quot;&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실행 결과는 다음과 같다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Hi!
abc

abc
abb para

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;참고-자료&quot;&gt;참고 자료&lt;/h1&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Unix shell script 학습 자료: &lt;a href=&quot;http://wiki.stunitas.com:8443/download/attachments/25996925/UNIX_13_bash_shell_script.pdf?version=1&amp;amp;modificationDate=1576655112000&amp;amp;api=v2&quot;&gt;UNIX_13_bash_shell_script.pdf&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bash 입문자를 위한 핵심 요약 정리 (Shell Script): &lt;a href=&quot;https://blog.gaerae.com/2015/01/bash-hello-world.html&quot;&gt;https://blog.gaerae.com/2015/01/bash-hello-world.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="Shell_script" /><summary type="html">이 문서는 Bash shell sciprt에 대해 학습한 부분들을 정리하고 공유하기 위해 작성하였다. 이 문서는 Bash schell script를 기준으로 작성하였다.</summary></entry><entry><title type="html">Kinesis Data stream의 제약조건 및 리샤딩 테스트</title><link href="http://localhost:4000/aws_kinesis_data_stream/kinesis_resharding_test/" rel="alternate" type="text/html" title="Kinesis Data stream의 제약조건 및 리샤딩 테스트" /><published>2020-01-31T00:00:00+09:00</published><updated>2020-01-31T00:00:00+09:00</updated><id>http://localhost:4000/aws_kinesis_data_stream/kinesis_resharding_test</id><content type="html" xml:base="http://localhost:4000/aws_kinesis_data_stream/kinesis_resharding_test/">&lt;h1 id=&quot;문서-목적&quot;&gt;문서 목적&lt;/h1&gt;

&lt;p&gt;이 문서는 AWS Kinesis Data stream의 제약조건과 리샤딩에 대한 테스트 결과를 남기기 위해 작성하였다.&lt;/p&gt;

&lt;p&gt;내용 중 실제 응답 결과에 대해 … 으로 표기한 부분은 가독성을 위해 생략한 것이다. 해당 부분 참고해 진행한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;테스트-결론&quot;&gt;테스트 결론&lt;/h1&gt;

&lt;p&gt;테스트가 많고 문서의 가독성을 위해 결론을 서두에 적는다.&lt;/p&gt;

&lt;p&gt;이 테스트에서는 AWS Kinesis의 제약조건을 테스트했으며 해당 제약조건은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;AWS Kinesis putRecords API의 제약조건 중 Record 파라미터 갯수 제한&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;AWS Kinesis 단일 샤드에 대한 입력 제약조건&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;초당 1000개의 Record 입력&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;초당 1Mb의 Record 입력&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;AWS Kinesis 리샤딩 기능&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;단일 샤드에서 2개의 샤드로 분할 시 Record가 중단되지 않고 입력되는 지 테스트&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;2개의 샤드에서 단일 샤드로 병합 시 Record가 중단되지 않고 입력되는 지 테스트&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위에 기술한 테스트 항목에 대해 테스트 진행 결과 &lt;strong&gt;AWS 공식문서에 기술된 AWS Kinesis의 제약조건은 유효함&lt;/strong&gt;을 확인했으며 &lt;strong&gt;AWS Kinesis를 리샤딩할 시에도 Record가 정상적으로 중단 없이 입력&lt;/strong&gt;됨을 확인했다.&lt;/p&gt;

&lt;p&gt;다만, AWS Kinesis의 단일 샤드에 대한 제약요건 중 초당 1000개의 Record 입력은 putRecords API를 1회 호출해 테스트한 것이므로 완벽하게 확인을 하지 못했다. 이 부분은 AWS Kinesis를 테스트한 다른 문서를 통해 더 명확하게 확인할 수 있다.([테스트] Kinesis Data Stream - 샤드당 제약 조건 확인)&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;테스트-환경&quot;&gt;테스트 환경&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 리전: 서울 리전&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 관련 서비스:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon Kinesis Data Stream&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon Kinesis Data Firsehose&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon Elasticsearch Service(이하 Amazon ES)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon S3&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                                                  Kinesis Data Firehose
                           Kinesis Stream        +----------------------+
  +---------+                +--------+          |  Event-1 - Stream-1  |                 +--------+
  | Sources |---------------&amp;gt;| Shard  |----------|         ...          |----------------&amp;gt;| AWS S3 |
  +---------+ data records   +--------+          |  Event-N - Stream-N  |        backup   +--------+
                             Data Stream         +----------------------+                   Bucket
                                                     Delivery Streams
                                                      (Event Stream)
                                                            |                             +---------------+
                                                            |                             | Elasticsearch |
                                                            +----------------------------&amp;gt;| Cluster       |&amp;lt;---&amp;gt;[Kibana]
                                                                                indexing  +---------------+      dashboard
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;테스트-환경-구성&quot;&gt;테스트 환경 구성&lt;/h1&gt;

&lt;h2 id=&quot;amazon-es-도메인&quot;&gt;Amazon ES 도메인&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;도메인 명:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Elasticsearch 6.5.4&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;인스턴스 구성&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;인스턴스 유형 : t2.small.elasticsearch (vCPU 1, Memory 2GiB)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;인스턴스 개수 : 2&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;인스턴스별 일반 EBS(SSD) 10GB 각 1개&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 인덱스 : test-seongwoo-data-stream&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;kinesis-data-stream-생성&quot;&gt;Kinesis Data Stream 생성&lt;/h2&gt;

&lt;p&gt;테스트용 Data Stream을 아래와 같은 설정으로 생성하였다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Kinesis Steram name : test-seongwoo-data-stream&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shard&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;샤드 수 : 1&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;쓰기 : 1 MB/초, 1000 레코드/초&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;읽기 : 2 MB/초&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;kinesis-data-firehose-delivery-stream-생성&quot;&gt;Kinesis Data Firehose Delivery Stream 생성&lt;/h2&gt;

&lt;p&gt;테스트용 Delivery Stream을 아래와 같은 설정으로 생성하였다. Source를 Kinesis Stream로 지정하였다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Delivery Stream name : test-seongwoo-firehose&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Source : Kinesis Stream&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Stream name : test-seongwoo-data-stream&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Index : test-seongwoo-data-stream&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Type : isc&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;No index rotation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Backup S3 bucket : sw-test123&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Delivery Stream buffer conditions for Elasticsearch&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;buffer size : 5 MB&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;buffer interval : 60 seconds&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;IAM role(역할)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon ES 도메인 ARN - firehose_delivery_role_seongwoo&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;직접 생성.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;테스트-delivery-stream-데이터-전송-및-s3-저장-형태-확인&quot;&gt;테스트: Delivery Stream 데이터 전송 및 S3 저장, 형태 확인&lt;/h1&gt;

&lt;p&gt;커넥츠 모바일에서 수집 될 것이라고 예상하는 데이터를 AWS Kinesis Data stream에 보내고 이를 delivery stream에서 Elasticsearch와 s3에 저장이 잘 되는 지 확인한다.&lt;/p&gt;

&lt;p&gt;또한, S3에 어떠한 형태로 저장되는 지 확인한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;user_id&quot;: 3322,
    &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
    &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
    &quot;device_manufacturer&quot;: &quot;LG&quot;,
    &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;,
    &quot;device_model&quot;: &quot;LM-G710N&quot;,
    &quot;device_os&quot;: &quot;Android&quot;,
    &quot;device_os_number&quot;: &quot;8.0&quot;,
    &quot;event&quot;: &quot;interest_service_click&quot;,
    &quot;interest_id&quot;: 1201,
    &quot;index&quot;: 1,
    &quot;interest_name&quot;: &quot;관심사&quot;,
    &quot;interest_service_id&quot;: null,
    &quot;interest_service_type&quot;: &quot;2&quot;,
    &quot;interest_service_name&quot;: &quot;3&quot;,
    &quot;timestamp&quot;: &quot;2019-04-30T07:30:00Z&quot;
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;aws config, credential 설정 관련된 부분은 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/cli-chap-configure.html&quot;&gt;AWS CLI 구성&lt;/a&gt; 문서를 참고하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 가상환경을 구성하고 boto3 라이브러리를 설치한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ python3 -m venv ./boto3_venv
$ source ./boto3_venv/bin/activate
$ pip3 install boto3

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래와 같은 파이썬 코드로 Kinesis Data Stream에 데이터를 전송하여 테스트 하였다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import boto3
import json
import sys
 

def get_kinesis_client():
    # Any clients created from this session will use credentials
    # from the [stseoul] section of ~/.aws/credentials
    # with stseoul profile.
    session = boto3.Session()
    kinesis = session.client(&quot;kinesis&quot;)
    return kinesis
 
 
# Test list up Kinesis Data Streams
def list_streams():
    kinesis = get_kinesis_client()
 
    print(&quot;List Kinesis Streams&quot;)
    response = kinesis.list_streams()
    print(response[&quot;StreamNames&quot;])
    return response
 
 
def describe_stream(stream_name=None):
    kinesis = get_kinesis_client()
 
    print(&quot;Describe Kinesis Streams&quot;)
    if stream_name is not None:
        response = kinesis.describe_stream(StreamName=stream_name)
    else:
        response = kinesis.describe_stream(StreamName=&quot;test-seongwoo-data-stream&quot;)
 
    print(response[&quot;StreamDescription&quot;])
    return response
 
 
# Test Record send to Data Streams
def put_record_to_data_stream():
    print(&quot;Put record to Data Stream&quot;)
 
    test_data = {
        &quot;user_id&quot;: 3322,
        &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
        &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
        &quot;device_manufacturer&quot;: &quot;LG&quot;,
        &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;,
        &quot;device_model&quot;: &quot;LM-G710N&quot;,
        &quot;device_os&quot;: &quot;Android&quot;,
        &quot;device_os_number&quot;: &quot;8.0&quot;,
        &quot;event&quot;: &quot;interest_service_click&quot;,
        &quot;interest_id&quot;: 1201,
        &quot;index&quot;: 1,
        &quot;interest_name&quot;: &quot;관심사&quot;,
        &quot;interest_service_id&quot;: None,
        &quot;interest_service_type&quot;: &quot;2&quot;,
        &quot;interest_service_name&quot;: &quot;3&quot;,
        &quot;timestamp&quot;: &quot;2019-05-03T08:04:00Z&quot;
    }
 
    kinesis = get_kinesis_client()
 
    response = kinesis.put_record(
        StreamName=&quot;test-seongwoo-data-stream&quot;,
        Data=json.dumps(test_data, ensure_ascii=False),
        PartitionKey=&quot;test-seongwoo-data-stream&quot;
    )
 
    print(response)
 
 
def put_records_to_data_stream():
    print(&quot;Put multiple records to Delivery Stream&quot;)
 
    test_data_list = [
        {
            &quot;user_id&quot;: 3322,
            &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
            &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
            &quot;device_manufacturer&quot;: &quot;LG&quot;, &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;, &quot;device_model&quot;: &quot;LM-G710N&quot;, &quot;device_os&quot;: &quot;Android&quot;, &quot;device_os_number&quot;: &quot;8.0&quot;,
            &quot;event&quot;: &quot;interest_service_click&quot;,
            &quot;interest_id&quot;: 1101,
            &quot;index&quot;: 1,
            &quot;interest_name&quot;: &quot;관심사&quot;, &quot;interest_service_id&quot;: None, &quot;interest_service_type&quot;: &quot;2&quot;,&quot;interest_service_name&quot;: &quot;5&quot;,
            &quot;timestamp&quot;: &quot;2019-05-03T08:10:00Z&quot;
        },
        {
            &quot;user_id&quot;: 3322,
            &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
            &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
            &quot;device_manufacturer&quot;: &quot;LG&quot;, &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;, &quot;device_model&quot;: &quot;LM-G710N&quot;, &quot;device_os&quot;: &quot;Android&quot;, &quot;device_os_number&quot;: &quot;8.0&quot;,
            &quot;event&quot;: &quot;interest_service_click&quot;,
            &quot;interest_id&quot;: 1301,
            &quot;index&quot;: 1,
            &quot;interest_name&quot;: &quot;관심사&quot;, &quot;interest_service_id&quot;: None, &quot;interest_service_type&quot;: &quot;3&quot;,&quot;interest_service_name&quot;: &quot;6&quot;,
            &quot;timestamp&quot;: &quot;2019-05-03T08:20:00Z&quot;
        },
        {
            &quot;user_id&quot;: 3322,
            &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
            &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
            &quot;device_manufacturer&quot;: &quot;LG&quot;, &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;, &quot;device_model&quot;: &quot;LM-G710N&quot;, &quot;device_os&quot;: &quot;Android&quot;, &quot;device_os_number&quot;: &quot;8.0&quot;,
            &quot;event&quot;: &quot;interest_service_click&quot;,
            &quot;interest_id&quot;: 1201,
            &quot;index&quot;: 1,
            &quot;interest_name&quot;: &quot;관심사&quot;, &quot;interest_service_id&quot;: None, &quot;interest_service_type&quot;: &quot;2&quot;,&quot;interest_service_name&quot;: &quot;3&quot;,
            &quot;timestamp&quot;: &quot;2019-05-03T08:30:00Z&quot;
        }
    ]
 
    # Data Stream에 batch로 넣을 데이터 구성
    records_list = list()
    for test_data in test_data_list:
        records_list.append({
            &quot;Data&quot;: json.dumps(test_data, ensure_ascii=False),
            &quot;PartitionKey&quot; : &quot;test-seongwoo-data-stream&quot;
            }
        )
 
    kinesis = get_kinesis_client()
 
    response = kinesis.put_records(
        StreamName=&quot;test-seongwoo-data-stream&quot;,
        Records=records_list
    )
 
    print(response)
 
 
def main():
    arg = sys.argv[1:]
    if &quot;list_stream&quot; in arg:
        list_streams()
    elif &quot;desc_stream&quot; in arg:
        describe_stream()
    elif &quot;put&quot; in arg:
        put_record_to_data_stream()
    elif &quot;batch&quot; in arg:
        put_records_to_data_stream()
    else:
        print(&quot;Unsupported test operation&quot;)
        print(&quot;Supported operations : ['list_stream', 'desc_stream', put', 'batch']&quot;)
 
 
 
if __name__ == &quot;__main__&quot;:
    main()

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;put_record() 메소드를 사용한 단일 데이터 전달과 put_record_batch() 메소드를 사용한 여러개의 데이터 전달에 대하여 동작을 테스트하였다.&lt;/p&gt;

&lt;p&gt;테스트 코드 실행 &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_steam.py desc_stream

Describe Kinesis Streams
{'StreamName': 'test-seongwoo-data-stream', ... }

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_steam.py list_stream

List Kinesis Streams
['test_kinesis', ... , 'test-seongwoo-data-stream']

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_steam.py put

Put record to Data Stream
{'ShardId': 'shardId-000000000000', ... }

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_steam.py batch

Put multiple records to Delivery Stream
{'FailedRecordCount': 0, 'Records': [{'SequenceNumber': '49599785146763097479697545100066493320130096649549643778', ... }

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;S3에 어떻게 저장되는 지 확인한다. 아래 내용은 공식 문서를 일부 발췌한 것이며 더 많은 내용은 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/basic-deliver.html#s3-object-name&quot;&gt;공식 사이트&lt;/a&gt;에서 확인 할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Amazon S3 객체 이름 형식&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Kinesis Data Firehose는 Amazon S3에 객체를 쓰기 전에 &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY/MM/DD/HH&lt;/code&gt; 형식으로 UTC 시간 접두사를 추가합니다. 이 접두사는 버킷에 논리적 계층 구조를 생성하는데, 계층 구조 내에서 슬래시(/) 하나당 한 계층을 생성합니다. 사용자 지정 접두사를 지정하여 이 구조를 수정할 수 있습니다. 사용자 지정 접두사를 지정하는 방법은 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/s3-prefixes.html&quot;&gt;Amazon S3 객체에 대한 사용자 지정 접두사&lt;/a&gt; 단원을 참조하십시오.&lt;/p&gt;

&lt;p&gt;Amazon S3 객체 이름은 &lt;code class=&quot;highlighter-rouge&quot;&gt;DeliveryStreamName-DeliveryStreamVersion-YYYY-MM-DD-HH-MM-SS-RandomString&lt;/code&gt;패턴을 따르는데, 여기에서 DeliveryStreamVersion는 1로 시작해 Kinesis Data Firehose 전송 스트림의 구성 변경이 이루어질 때마다 1씩 증가합니다. 전송 스트림 구성(예: S3 버킷 이름, 버퍼링 힌트, 압축, 암호화)을 변경할 수 있습니다. 이 작업은 Kinesis Data Firehose 콘솔 또는 &lt;a href=&quot;https://docs.aws.amazon.com/firehose/latest/APIReference/API_UpdateDestination.html&quot;&gt;UpdateDestination&lt;/a&gt; API 작업을 사용하여 수행할 수 있습니다.&lt;/p&gt;

&lt;p&gt;S3는 다음과 같이 저장된다.&lt;/p&gt;

&lt;p&gt;Key: 2019/09/24/05/test-seongwoo-firehose-1-2019-09-24-05-06-28-818e40dd-2318-4258-88cc-3c66a08eba10&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{&quot;user_id&quot;: &quot;DUUUQMY-tx5Qy8e-DWtQW9q&quot;, &quot;app_version&quot;: &quot;v1.5.16(90)&quot;, &quot;device_id&quot;: &quot;2dlGCh-V3uaaM-qyyp3r-kWMnEZ-8SGAAD&quot;, &quot;device_manufacturer&quot;: &quot;Apple&quot;, &quot;device_name&quot;: &quot;Apple Iphone1&quot;, &quot;device_model&quot;: &quot;noZL-sFj5&quot;, &quot;device_os&quot;: &quot;IOS&quot;, &quot;device_os_number&quot;: 46.0, &quot;event&quot;: &quot;my_page_serivce_click&quot;, &quot;interest_id&quot;: &quot;4569&quot;, &quot;index&quot;: &quot;1&quot;, &quot;interest_name&quot;: &quot;422&quot;, &quot;interest_service_id&quot;: null, &quot;interest_service_type&quot;: &quot;33&quot;, &quot;interest_service_name&quot;: &quot;3335&quot;, &quot;timestamp&quot;: &quot;2019-07-18T19:43:40Z&quot;}{&quot;user_id&quot;: &quot;an0s9wG-xgyregq-5XwO4BR&quot;, &quot;app_version&quot;: &quot;v7.74.23(55)&quot;, &quot;device_id&quot;: &quot;6gBC5m-r9SIhn-RGJ4bU-rMJPSt-gPqE6J&quot;, &quot;device_manufacturer&quot;: &quot;Huawei&quot;, &quot;device_name&quot;: &quot;Huawei Nova3&quot;, &quot;device_model&quot;: &quot;M2A6-HG7q&quot;, &quot;device_os&quot;: &quot;Android&quot;, &quot;device_os_number&quot;: 77.0, &quot;event&quot;: &quot;my_page_serivce_click&quot;, &quot;interest_id&quot;: &quot;2342&quot;, &quot;index&quot;: &quot;3&quot;, &quot;interest_name&quot;: &quot;343&quot;, &quot;interest_service_id&quot;: null, &quot;interest_service_type&quot;: &quot;545&quot;, &quot;interest_service_name&quot;: &quot;3&quot;, &quot;timestamp&quot;: &quot;2019-04-12T20:24:16Z&quot;}
...
하략
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;테스트-aws-kinesis-putrecords-api-입력-제한-테스트&quot;&gt;테스트: AWS Kinesis putRecords API 입력 제한 테스트&lt;/h1&gt;

&lt;p&gt;AWS Kinesis Data stream service API의 putRecords 제한 조건은 다음과 같다. 이 내용은 &lt;a href=&quot;https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecords.html&quot;&gt;공식 사이트&lt;/a&gt;에서 확인 할 수 있다.&lt;/p&gt;

&lt;p&gt;Each PutRecords request can support up to 500 records. Each record in the request can be as large as 1 MiB, up to a limit of 5 MiB for the entire request, including partition keys. Each shard can support writes up to 1,000 records per second, up to a maximum data write total of 1 MiB per second.&lt;/p&gt;

&lt;p&gt;테스트는 다음과 같이 진행한다. 아래의 제약조건을 제외한 나머지 제약조건에 대한 부분(1개의 레코드에 대한 용량이 1Mb를 넘을 수 없다는 것, 1개 API 호출 시 모든 파라미터의 용량 합이 5메가를 넘을 수 없다는 것)은 실제 운용 시 해당 제약조건을 초과하거나 근접하게 운용하는 일이 발생할 확률이 낮을 것이라 생각해 제외했다.&lt;/p&gt;

&lt;h3 id=&quot;테스트putrecords-api의-records-파라미터의-record-갯수가-500개-이상을-입력했을-경우&quot;&gt;테스트: putRecords API의 Records 파라미터의 Record 갯수가 500개 이상을 입력했을 경우&lt;/h3&gt;

&lt;p&gt;테스트한 코드는 위에 첨부된 “Kinesis Data Stream test python code sample” Code block에 있는 것을 부분 수정해 진행했다. 위의 코드 중 put_Records의 파라미터만 바꿔 진행한 것이므로 따로 코드를 남겨놓지 않는다.&lt;/p&gt;

&lt;p&gt;테스트를 위해 putRecords API에 Record 1000개를 넣어 AWS Kinesis에 입력했다. &lt;/p&gt;

&lt;p&gt;실행 명령은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ (.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_stream_seongwoo.py &amp;gt; test.log 2&amp;gt;&amp;amp;1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과는 다음과 같다&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;start data generator
Put record to Data Stream

response: {'ShardId': 'shardId-000000000000', ... }
Successfully put record
Put multiple records to Delivery Stream
Traceback (most recent call last):
  File &quot;test_sender_kinesis_data_stream_seongwoo.py&quot;, line 150, in &amp;lt;module&amp;gt;
    main()
  File &quot;test_sender_kinesis_data_stream_seongwoo.py&quot;, line 145, in main
    put_records_to_data_stream(1000, 3)
  File &quot;test_sender_kinesis_data_stream_seongwoo.py&quot;, line 136, in put_records_to_data_stream
    response = send_records_to_kinesis(record_list)
  File &quot;test_sender_kinesis_data_stream_seongwoo.py&quot;, line 107, in send_records_to_kinesis
    Records=records_list
  File &quot;/Users/st/test/kinesis_test_poc/.venv/lib/python3.7/site-packages/botocore/client.py&quot;, line 357, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File &quot;/Users/st/test/kinesis_test_poc/.venv/lib/python3.7/site-packages/botocore/client.py&quot;, line 661, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (ValidationException) when calling the PutRecords operation: 1 validation error detected: Value '[PutRecordsRequestEntry(data=java.nio.HeapByteBuffer[pos=0 lim=503 cap=503], explicitHashKey=null, 
partitionKey=test-seongwoo-data-stream), PutRecordsRequestEntry(data=java.nio.HeapByteBuffer[pos=0 lim=521 cap=521], explicitHashKey=null, partitionKey=test-seongwoo-data-stream), PutRecordsRequestEntry(data=java.nio.HeapByteBuffer[pos=0 lim=503 cap=503], explicitHashKey=null, 

...
같은 형식의 내용이 반복되어 중략한다.
...

partitionKey=test-seongwoo-data-stream), PutRecordsRequestEntry(data=java.nio.HeapByteBuffer[pos=0 lim=518 cap=518], explicitHashKey=null, partitionKey=test-seongwoo-data-stream)]' at 'records' failed to satisfy constraint: Member must have length less than or equal to 500
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Record 갯수를 1000개로 넣었을 때, AWS Kinesis API putRecords는 오류가 발생했으며 S3를 확인 결과 아무런 데이터도 기록되지 않았다.&lt;/p&gt;

&lt;p&gt;또한, AWS Kinesis 모니터링 콘솔에서도 데이터 입력이 0으로 표시되었다. 이 결과를 통해 다음과 같은 사실을 알 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;500개를 초과한 Record를&lt;/strong&gt; putRecords API에 파라미터로 넣어 API 호출 시 에러가 발생하며 해당 Records는 &lt;strong&gt;AWS Kinesis에&lt;/strong&gt; &lt;strong&gt;전부 입력되지 않는다.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1000개를 넣었을 경우 에러가 발생한다는 것을 확인했다. 오류 메시지를 보면 “put_records API의 Member는 500개와 동등하거나 낮은 수준이여야 한다”라는 부분이 있다. 그래서 확인해보기 위해 records 갯수를 500개로 바꿔 진행했다.&lt;/p&gt;

&lt;p&gt;실행 명령은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ (.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_stream_seongwoo.py &amp;gt; test.log 2&amp;gt;&amp;amp;1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;start data generator
Put multiple records to Delivery Stream
size record: 4272
{'FailedRecordCount': 0, 'Records': [{'SequenceNumber': '49600332740223402687238218016128099187294154588323578050', ...

...
중략
...

... 'content-length': '55535'}, 'RetryAttempts': 0}}
time : 0.7376766204833984
end data generator


&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;S3에 제대로 데이터가 저장되어 있는 지 확인한다. S3에 정상적으로 저장되었는 지 확인하기 위해 Test Key의 Value를 데이터 순서에 따라 1씩 증가하게 넣었다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{&quot;test&quot;: 0}{&quot;test&quot;: 1}{&quot;test&quot;: 2}{&quot;test&quot;: 3}{&quot;test&quot;: 4}{&quot;test&quot;: 5}{&quot;test&quot;: 6}{&quot;test&quot;: 7}{&quot;test&quot;: 8}{&quot;test&quot;: 9}{&quot;test&quot;: 10}{&quot;test&quot;: 11}{&quot;test&quot;: 12}{&quot;test&quot;: 13}{&quot;test&quot;: 14}{&quot;test&quot;: 15}{&quot;test&quot;: 16}{&quot;test&quot;: 17}{&quot;test&quot;: 18}{&quot;test&quot;: 19}{&quot;test&quot;: 20}{&quot;test&quot;: 21}{&quot;test&quot;: 22}{&quot;test&quot;: 23}{&quot;test&quot;: 24}{&quot;test&quot;: 25}{&quot;test&quot;: 26}{&quot;test&quot;: 27}{&quot;test&quot;: 28}{&quot;test&quot;: 29}{&quot;test&quot;: 30}{&quot;test&quot;: 31}{&quot;test&quot;: 32}{&quot;test&quot;: 33}{&quot;test&quot;: 34}{&quot;test&quot;: 35}{&quot;test&quot;: 36}{&quot;test&quot;: 37}{&quot;test&quot;: 38}{&quot;test&quot;: 39}{&quot;test&quot;: 40}{&quot;test&quot;: 41}{&quot;test&quot;: 42}{&quot;test&quot;: 43}{&quot;test&quot;: 44}{&quot;test&quot;: 45}{&quot;test&quot;: 46}{&quot;test&quot;: 47}{&quot;test&quot;: 48}{&quot;test&quot;: 49}{&quot;test&quot;: 50}{&quot;test&quot;: 51}{&quot;test&quot;: 52}{&quot;test&quot;: 53}{&quot;test&quot;: 54}{&quot;test&quot;: 55}{&quot;test&quot;: 56}{&quot;test&quot;: 57}{&quot;test&quot;: 58}{&quot;test&quot;: 59}{&quot;test&quot;: 60}{&quot;test&quot;: 61}{&quot;test&quot;: 62}{&quot;test&quot;: 63}{&quot;test&quot;: 64}{&quot;test&quot;: 65}{&quot;test&quot;: 66}{&quot;test&quot;: 67}{&quot;test&quot;: 68}{&quot;test&quot;: 69}{&quot;test&quot;: 70}{&quot;test&quot;: 71}{&quot;test&quot;: 72}{&quot;test&quot;: 73}{&quot;test&quot;: 74}{&quot;test&quot;: 75}{&quot;test&quot;: 76}{&quot;test&quot;: 77}{&quot;test&quot;: 78}{&quot;test&quot;: 79}{&quot;test&quot;: 80}{&quot;test&quot;: 81}{&quot;test&quot;: 82}{&quot;test&quot;: 83}{&quot;test&quot;: 84}{&quot;test&quot;: 85}{&quot;test&quot;: 86}{&quot;test&quot;: 87}{&quot;test&quot;: 88}{&quot;test&quot;: 89}{&quot;test&quot;: 90}{&quot;test&quot;: 91}{&quot;test&quot;: 92}{&quot;test&quot;: 93}{&quot;test&quot;: 94}{&quot;test&quot;: 95}{&quot;test&quot;: 96}{&quot;test&quot;: 97}{&quot;test&quot;: 98}{&quot;test&quot;: 99}{&quot;test&quot;: 100}{&quot;test&quot;: 101}{&quot;test&quot;: 102}{&quot;test&quot;: 103}{&quot;test&quot;: 104}{&quot;test&quot;: 105}{&quot;test&quot;: 106}{&quot;test&quot;: 107}{&quot;test&quot;: 108}{&quot;test&quot;: 109}{&quot;test&quot;: 110}{&quot;test&quot;: 111}{&quot;test&quot;: 112}{&quot;test&quot;: 113}{&quot;test&quot;: 114}{&quot;test&quot;: 115}{&quot;test&quot;: 116}{&quot;test&quot;: 117}{&quot;test&quot;: 118}{&quot;test&quot;: 119}{&quot;test&quot;: 120}{&quot;test&quot;: 121}{&quot;test&quot;: 122}

...
중략
...

{&quot;test&quot;: 497}{&quot;test&quot;: 498}{&quot;test&quot;: 499}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;API 응답 메세지의 FailedRecordCount가 0이라는 것과 S3에 정상적으로 입력된 데이터 로그를 통해 putRecords API가 오류 메시지 없이 정상적으로 실행 되었다는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;위의 결과를 통해 다음과 같은 사실을 알 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kinesis API putRecords 제약조건은 AWS Kinesis API 공식 개발문서에 있는 제약 조건과 같으며 500개 이하까지만 입력이 가능하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;테스트-aws-kinesis-data-stream-초당-1000개-또는-1mb-전송&quot;&gt;테스트: AWS Kinesis Data Stream 초당 1000개 또는 1MB 전송&lt;/h1&gt;

&lt;p&gt;AWS Kinesis Data stream의 Input 제한 조건은 다음과 같다. 일부를 발췌해 아래에 기술하였으며 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/streams/latest/dev/service-sizes-and-limits.html&quot;&gt;공식 사이트 링크&lt;/a&gt;를 통해 더 많은 내용을 확인할 수 있다. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kinesis Data Streams 제한&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Amazon Kinesis Data Streams에는 다음과 같은 스트림 및 샤드 제한이 적용됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;한 스트림 또는 한 계정에서 사용할 수 있는 샤드 수는 상한이 없습니다. 일반적으로 한 워크로드에는 수천 개의 샤드가 하나의 스트림에 포함되어 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;단일 계정에서 사용할 수 있는 스트림 수는 상한이 없습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;개별 샤드는 초당 1MiB의 데이터(파티션 키 포함) 또는 초당 레코드 1,000개를 수집해 쓸 수 있습니다. 마찬가지로, 스트림을 샤드 5,000개로 확장하면 해당 스트림은 초당 5GiB나 레코드 5백만 개를 수집할 수 있습니다. 추가 수집 용량이 필요한 경우 AWS Management 콘솔 또는&lt;a href=&quot;https://docs.aws.amazon.com/kinesis/latest/APIReference/API_UpdateShardCount.html&quot;&gt;UpdateShardCount&lt;/a&gt; API를 사용하여 스트림의 샤드 수를 쉽게 확장할 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;AWS 리전 미국 동부(버지니아 북부), 미국 서부(오레곤) 및 EU(아일랜드)의 기본 샤드 제한은 500개이고 다른 모든 리전의 기본 샤드 제한은 200개입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Base64 인코딩 전 레코드의 데이터 페이로드 최대 크기는 1MiB입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html&quot;&gt;GetRecords&lt;/a&gt;는 단일 샤드에서 호출당 최대 10MiB 데이터와 호출당 최대 레코드 10,000개를 검색할 수 있습니다. 모든 GetRecords 호출은 1개의 읽기 트랜잭션으로 간주됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;각 샤드는 초당 최대 5개의 읽기 트랜잭션을 지원합니다. 각 읽기 트랜잭션은 최대 10,000개의 레코드를 제공하며, 트랜잭션당 상한은 10MiB입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;각 샤드는 &lt;a href=&quot;https://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html&quot;&gt;GetRecords&lt;/a&gt;를 통해 초당 2MiB의 최대 총 데이터 읽기 속도를 지원합니다. GetRecords 호출이 10MiB를 반환하면, 다음 5초 안에 이루어지는 호출에서 예외가 발생합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;스트림당 최대 20명의 소비자를 등록하여 &lt;a href=&quot;https://docs.aws.amazon.com/streams/latest/dev/introduction-to-enhanced-consumers.html&quot;&gt;향상된 팬아웃&lt;/a&gt;을 사용할 수 있습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 제약 조건 중 Data stream 쓰기 제약조건에 대해 테스트를 진행한다. 테스트는 다음과 같이 진행한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;초당 1000개의 Record 입력&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;초당 1Mb의 Record 입력&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;테스트-초당-1000개의record입력&quot;&gt;테스트: 초당 1000개의 Record 입력 &lt;/h2&gt;

&lt;p&gt;테스트한 코드는 위에 첨부된 “Kinesis Data Stream test python code sample” Code block에 있는 것을 부분 수정해 진행했다. 위의 코드 중 putRecords의 파라미터만 바꿔 진행한 것이므로 따로 코드를 남겨놓지 않는다.&lt;/p&gt;

&lt;p&gt;테스트 하기 위해 Python Time 모듈을 이용해 처음 AWS Kinesis API 호출부터 AWS Kinesis API Response를 받는 시점까지 측정했다.&lt;/p&gt;

&lt;p&gt;AWS Kinesis putRecords의 Record 파라미터 갯수 제약조건으로 인해 1회 호출 시 Record 500개를 Kinesis에 입력했다. 3회 반복해 총 1500개의 Records를 입력했다. 각 각의 Record의 value들은 0부터 499까지의 값을 차례대로 부여했다.&lt;/p&gt;

&lt;p&gt;실행 명령은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ (.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_stream_seongwoo.py &amp;gt; test.log 2&amp;gt;&amp;amp;1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과는 다음과 같다&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;start data generator
Put multiple records to Delivery Stream
size record_list: 4272
{'FailedRecordCount': 0, 'Records': [{'SequenceNumber': '49599785146763097479698356765197192885873289808377282562', ... ,'ShardId': 'shardId-000000000000'}, 

중략
...

 'HTTPHeaders': {'x-amzn-requestid': 'ea1bdd1e-d9b6-02ee-bc0f-21cacc407fd6', 'x-amz-id-2': '+n7mT++dLSc28TxENLwUQSx4nT99aM9EWnP3IxiGC43u63LUpEwJr3ClKIGY2cPkgHmzTGsNOa7TK5CqvCJyXOcHkXg+k1HX', 'date': 'Mon, 7 Oct 2019 08:43:00 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '55535'}, 'RetryAttempts': 0}}
size record_list: 4272
{'FailedRecordCount': 0, 'Records': [{'SequenceNumber': '49599785146763097479698356765996292852638559692858064898', ..., 'ShardId': 'shardId-000000000000'},

중략
...

 'HTTPStatusCode': 200, ... 'ShardId': 'shardId-000000000000'}, 

중략
...

'HTTPStatusCode': 200, ... 'content-length': '55535'}, 'RetryAttempts': 0}}
time : 0.46463775634765625
end data generator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과를 통해 0.46초안에 AWS Kinesis에 1500개의 Records가 입력되었다는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;S3에 제대로 데이터가 저장되어 있는 지 확인한다.&lt;/p&gt;

&lt;p&gt;아래의 결과는 보기 쉽게 중간의 부분을 생략하였으며 실제는 줄바꿈 없이 연속되어 Record가 입력되었다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{&quot;test&quot;: 0}{&quot;test&quot;: 1}{&quot;test&quot;: 2}{&quot;test&quot;: 3}{&quot;test&quot;: 4}{&quot;test&quot;: 5} 

...

{&quot;test&quot;: 497}{&quot;test&quot;: 498}{&quot;test&quot;: 499}{&quot;test&quot;: 0}{&quot;test&quot;: 1}{&quot;test&quot;: 2}{&quot;test&quot;: 3}{&quot;test&quot;: 4}{&quot;test&quot;: 5}

...

{&quot;test&quot;: 497}{&quot;test&quot;: 498}{&quot;test&quot;: 499}{&quot;test&quot;: 0}{&quot;test&quot;: 1}{&quot;test&quot;: 2}{&quot;test&quot;: 3}{&quot;test&quot;: 4}{&quot;test&quot;: 5}

...

{&quot;test&quot;: 497}{&quot;test&quot;: 498}{&quot;test&quot;: 499}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;API 응답 메세지의 FailedRecordCount가 0이라는 것과 S3에 정상적으로 입력된 데이터 로그를 통해 putRecords API가 오류 메시지 없이 정상적으로 실행 되었다는 것을 확인할 수 있다. S3의 로그는 0~499까지의 값이 3번 반복됨을 확인할 수 있다. &lt;/p&gt;

&lt;p&gt;위의 결과를 통해 다음과 같은 사실을 알 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;AWS Kinesis Data stream은 &lt;strong&gt;초당 1000개 이상의 입력을 받을 수 있다&lt;/strong&gt;. 그러나 문서에 AWS Kinesis 입력 제한이 초당 1000개이므로 1000개까지만 입력하는 것을 권장한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;테스트-초당-1mb의record입력&quot;&gt;테스트: 초당 1Mb의 Record 입력&lt;/h2&gt;

&lt;p&gt;테스트한 코드는 위에 첨부된 “Kinesis Data Stream test python code sample” Code block에 있는 것을 부분 수정해 진행했다. 위의 코드 중 putRecords의 파라미터만 바꿔 진행한 것이므로 따로 코드를 남겨놓지 않는다.&lt;/p&gt;

&lt;p&gt;Record 갯수는 20개씩 보냈으며 Record 한개의 key의 Value에 list로 묶은 문자열을 보냈다. 보낸 Record를 파일로 남겨 용량을 측정했다. 각 각의 Record의 value들은 0부터 8999까지의 값을 차례대로 부여했다.&lt;/p&gt;

&lt;p&gt;실행 명령은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ (.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_stream_seongwoo.py &amp;gt; test.log 2&amp;gt;&amp;amp;1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{'FailedRecordCount': 0, 'Records': [{'SequenceNumber': '49599785146763097479698550723467690569786003296706625538', 'ShardId': 'shardId-000000000000'}, ... 'x-amz-id-2': 'GogLEyz7V3+EFIneHaCt+mFeP+XscMmpKgF5BUZttI2j4PeejACvIhqFK0UrMtkeL2dLbf4GEaco/F4/ersaDeALCvjNpb5s', 'date': 'Thu, 10 Oct 2019 09:18:56 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2255'}, 'RetryAttempts': 0}}
time : 0.31870388984680176
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;S3에 제대로 데이터가 저장되어 있는 지 확인한다. S3에 정상적으로 저장되었는 지 확인하기 위해 Test Key의 Value를 데이터 순서에 따라 1씩 증가하게 넣었다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{&quot;test&quot;: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,

...
중략
...

8954, 8955, 8956, 8957, 8958, 8959, 8960, 8961, 8962, 8963, 8964, 8965, 8966, 8967, 8968, 8969, 8970, 8971, 8972, 8973, 8974, 8975, 8976, 8977, 8978, 8979, 8980, 8981, 8982, 8983, 8984, 8985, 8986, 8987, 8988, 8989, 8990, 8991, 8992, 8993, 8994, 8995, 8996, 8997, 8998, 8999]}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;API 응답 메세지의 FailedRecordCount가 0이라는 것과 S3에 정상적으로 입력된 데이터 로그를 통해 putRecords API가 오류 메시지 없이 정상적으로 실행 되었다는 것을 확인할 수 있다. S3의 로그를 통해 0~8999까지의 값이 정상적으로 기록된 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;보낸 Records를 저장한 File의 용량은 1.1Mb이다. 0.318초의 응답시간안에 1.1Mb를 보냈으니 초당 1Mb 입력이 되는듯 하지만 실제 &lt;strong&gt;로컬 맥의 시간과 AWS Kinesis의 시간이 동기화되어 처리가 되지 않으므로&lt;/strong&gt; 명확하게 테스트 되지 않는 부분이 있어 더 많은 데이터를 보내어 테스트 하려고 한다.&lt;/p&gt;

&lt;p&gt;20개, 용량은 1.1Mb Records를 3번 AWS Kinesis에 입력한다. 위와 다른 점은 Record의 key, value 값 중 Test key의 Value를 ‘a’로 했다. 그 이유는 숫자를 증가시켜 입력할 경우 처리 속도가 느려 원하는 성능이 나오지 않기 때문이다. &lt;/p&gt;

&lt;p&gt;실행 명령은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ (.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_stream_seongwoo.py &amp;gt; test.log 2&amp;gt;&amp;amp;1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{'FailedRecordCount': 0, 'Records': [{'SequenceNumber': '49599785146763097479698551505547190720701591040607387650', 'ShardId': 'shardId-000000000000'}, {'SequenceNumber': '49599785146763097479698551505548399646521205669782093826', 'ShardId': 'shardId-000000000000'}, {'SequenceNumber': '49599785146763097479698551505549608572340820298956800002', 'ShardId': 'shardId-000000000000'}, {'SequenceNumber': '49599785146763097479698551505550817498160434928131506178', 'ShardId': 'shardId-000000000000'}, {'SequenceNumber': '49599785146763097479698551505552026423980049557306212354', ... 'content-length': '2477'}, 'RetryAttempts': 0}}
time : 2.4904608726501465

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;S3에 제대로 데이터가 저장되어 있는 지 확인했으나 ‘a’값을 일일이 세어볼 수 없으므로 해당 리턴 메시지로 파악을 진행한다.&lt;/p&gt;

&lt;p&gt;리턴 메시지로 봤을 때, 총 60개의 Records 중 17개가 실패했다. 총 용량 3.3Mb이며 완료 시간은 2.49초이다. 17개는 약 0.937Mb이며 실패한 용량을 제외한 Records의 용량은 2.365Mb이다. &lt;/p&gt;

&lt;p&gt;이를 수행한 시간으로 나눠 초당 처리한 용량을 계산하면 0.9497Mb이며 여러 가지 변수에 의한 오차를 감안하면 초당 약 1Mb에 근접한다고 볼 수 있다.&lt;/p&gt;

&lt;p&gt;위의 결과를 통해 &lt;strong&gt;AWS Kinesis의 초당 1Mb 제약조건이 유효함을 확인했다.&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;테스트-aws-kinesis-data-stream-리샤딩-기능-테스트&quot;&gt;테스트: AWS Kinesis Data Stream 리샤딩 기능 테스트&lt;/h1&gt;

&lt;p&gt;AWS Kinesis 개발자 문서에서는 Kinesis data stream이 리샤딩 기능을 지원한다고 명시되어 있다. AWS Kinesis를 Production 환경에서 운용할 경우 리샤딩중에도 데이터가 입력되는 경우가 생길 수 있어 테스트를 진행한다.&lt;/p&gt;

&lt;p&gt;이 테스트는 아래와 같은 경우를 테스트하기 위해 실시한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;샤드가 1개에서 2개로 분할 되었을 때 분할 과정에서 데이터가 정상적으로 입력이 되는 지 테스트한다.  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;샤드가 2개에서 1개로 병합 되었을 때 병합 과정에서 데이터가 정상적으로 입력이 되는 지 테스트한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;테스트-샤드-1개에서-2개로-분할&quot;&gt;테스트: 샤드 1개에서 2개로 분할&lt;/h2&gt;

&lt;p&gt;테스트는 아래와 같은 순서로 진행된다. 테스트 데이터 입력이 제대로 되었는 지 확인을 위해 Value값은 1부터 차례대로 1씩 증가하게 값을 입력했다. &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;AWS Kinesis 샤드 1개로 구성한 후 0.5초마다 500개의 Records를 AWS Kinesis에 100회 반복해 입력한다. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;입력 과정 중 AWS Kinesis 콘솔에서 샤드를 1개에서 2개로 변경한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;변경이 정상적으로 끝난 것을 콘솔에서 확인 후 S3에 남겨진 로그와 API 리턴 메시지를 통해 정상적 입력이 되었는 지 확인한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;실행 명령은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ (.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_stream_seongwoo.py &amp;gt; test.log 2&amp;gt;&amp;amp;1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음은 AWS Kinesis 콘솔에서 샤드 1개임을 확인한 스크린샷이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/kinesis1.jpg&quot; alt=&quot;kinesis1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{'FailedRecordCount': 0, 'Records': [{'SequenceNumber': ... 'ShardId': 'shardId-000000000006'}, {'SequenceNumber': 

...
중략
...

2019 08:58:54 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '55535'}, 'RetryAttempts': 0}}
time : 73.51617002487183
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;응답 메시지가 너무 길어 중간에 생략하였다.&lt;/p&gt;

&lt;p&gt;메시지를 통해 모든 Records이 정상적으로 입력 되었음을 확인했다.&lt;/p&gt;

&lt;p&gt;다음은 성공적으로 샤드가 변경되었다는 콘솔 메시지를 캡쳐한 사진이다.&lt;/p&gt;

&lt;p&gt;변경 후 Open shards는 2개가 되었으며 Closed shards가 6에서 7로 1이 더해진 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/kinesis2.jpg&quot; alt=&quot;kinesis2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;로그는 2개의 파일에 나눠 기록되었다. 해당 파일의 키값은 다음과 같다.&lt;/p&gt;

&lt;p&gt;2019/10/11/09/test-seongwoo-firehose-2-2019-10-11-09-23-02-b3a6dd32-fb83-419f-bb6d-db30becb3d14, 2019/10/11/09/test-seongwoo-firehose-2-2019-10-11-09-22-43-de40823e-7801-470b-b62e-333c3f8c176a&lt;/p&gt;

&lt;p&gt;아래는 위에 기술한 2개 파일의 S3 로그 메시지이다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{&quot;test&quot;: 0}{&quot;test&quot;: 1}{&quot;test&quot;: 2}{&quot;test&quot;: 3}{&quot;test&quot;: 4}{&quot;test&quot;: 5}{&quot;test&quot;: 6}{&quot;test&quot;: 7}{&quot;test&quot;: 8}{&quot;test&quot;: 9}{&quot;test&quot;: 10}{&quot;test&quot;: 11}{&quot;test&quot;: 12}{&quot;test&quot;: 13}{&quot;test&quot;: 14}{&quot;test&quot;: 15}{&quot;test&quot;: 16}{&quot;test&quot;: 17}{&quot;test&quot;: 18}{&quot;test&quot;: 19}{&quot;test&quot;: 20}{&quot;test&quot;: 21}{&quot;test&quot;: 22}{&quot;test&quot;: 23}

...
중략
...

{&quot;test&quot;: 49990}{&quot;test&quot;: 49991}{&quot;test&quot;: 49992}{&quot;test&quot;: 49993}{&quot;test&quot;: 49994}{&quot;test&quot;: 49995}{&quot;test&quot;: 49996}{&quot;test&quot;: 49997}{&quot;test&quot;: 49998}{&quot;test&quot;: 49999}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;API 응답 메세지의 FailedRecordCount가 0이라는 것과 S3에 정상적으로 입력된 데이터 로그를 통해 putRecords API가 오류 메시지 없이 정상적으로 실행 되었다는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;위의 결과를 통해 샤드가 1개에서 2개로 분할되는 과정에서 정상적으로 데이터가 AWS Kinesis에 입력되고 있음을 확인할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;테스트-샤드-2개에서-1개로-병합&quot;&gt;테스트: 샤드 2개에서 1개로 병합&lt;/h2&gt;

&lt;p&gt;테스트는 아래와 같은 순서로 진행된다. 테스트 데이터 입력이 제대로 되었는 지 확인을 위해 Value값은 1부터 차례대로 1씩 증가하게 값을 입력했다. &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;AWS Kinesis 샤드 1개로 구성한 후 0.5초마다 500개의 Records를 AWS Kinesis에 100회 반복해 입력한다. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;입력 과정 중 AWS Kinesis 콘솔에서 샤드를 2개에서 1개로 변경한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;변경이 정상적으로 끝난 것을 콘솔에서 확인 후 S3에 남겨진 로그와 API 리턴 메시지를 통해 정상적 입력이 되었는 지 확인한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;실행 명령은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ (.venv) ➜  kinesis_test_poc python test_sender_kinesis_data_stream_seongwoo.py &amp;gt; test.log 2&amp;gt;&amp;amp;1

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음은 AWS Kinesis 콘솔에서 샤드 2개임을 확인한 스크린샷이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/kinesis3.jpg&quot; alt=&quot;kinesis3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;결과는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{'FailedRecordCount': 0, 'Records': [{'SequenceNumber': '49600331525144999800098489595455988878940239397411356770', 'ShardId': 'shardId-000000000006'}

...
중략
...

2019 08:58:54 GMT', 'content-type': 'application/x-amz-json-1.1', 'content-length': '55535'}, 'RetryAttempts': 0}}
time : 72.90893507003784
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;응답 메시지가 너무 길어 중간에 생략하였다.&lt;/p&gt;

&lt;p&gt;메시지를 통해 모든 Records이 정상적으로 입력 되었음을 확인했다.&lt;/p&gt;

&lt;p&gt;다음은 성공적으로 샤드가 변경되었다는 콘솔 메시지를 캡쳐한 사진이다.&lt;/p&gt;

&lt;p&gt;변경 후 Open shards는 1개가 되었으며 Closed shards가 10에서 12로 2가 더해진 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/kinesis4.jpg&quot; alt=&quot;kinesis4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;로그는 2개의 파일에 나눠 기록되었다. 해당 파일의 키값은 다음과 같다.&lt;/p&gt;

&lt;p&gt;2019/10/11/09/test-seongwoo-firehose-2-2019-10-11-09-23-02-b3a6dd32-fb83-419f-bb6d-db30becb3d14, 2019/10/11/09/test-seongwoo-firehose-2-2019-10-11-09-22-43-de40823e-7801-470b-b62e-333c3f8c176a&lt;/p&gt;

&lt;p&gt;아래는 위에 기술한 2개 파일의 S3 로그 메시지이다. &lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{&quot;test&quot;: 0}{&quot;test&quot;: 1}{&quot;test&quot;: 2}{&quot;test&quot;: 3}{&quot;test&quot;: 4}{&quot;test&quot;: 5}{&quot;test&quot;: 6}{&quot;test&quot;: 7}{&quot;test&quot;: 8}{&quot;test&quot;: 9}{&quot;test&quot;: 10}{&quot;test&quot;: 11}{&quot;test&quot;: 12}{&quot;test&quot;: 13}{&quot;test&quot;: 14}{&quot;test&quot;: 15}{&quot;test&quot;: 16}{&quot;test&quot;: 17}{&quot;test&quot;: 18}{&quot;test&quot;: 19}{&quot;test&quot;: 20}{&quot;test&quot;: 21}{&quot;test&quot;: 22}{&quot;test&quot;: 23}

...
중략
...

{&quot;test&quot;: 49990}{&quot;test&quot;: 49991}{&quot;test&quot;: 49992}{&quot;test&quot;: 49993}{&quot;test&quot;: 49994}{&quot;test&quot;: 49995}{&quot;test&quot;: 49996}{&quot;test&quot;: 49997}{&quot;test&quot;: 49998}{&quot;test&quot;: 49999}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;API 응답 메세지의 FailedRecordCount가 0이라는 것과 S3에 정상적으로 입력된 데이터 로그를 통해 putRecords API가 오류 메시지 없이 정상적으로 실행 되었다는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;위의 결과를 통해 샤드가 1개에서 2개로 분할되는 과정에서 정상적으로 데이터가 AWS Kinesis에 입력되고 있음을 확인할 수 있다.&lt;/p&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="AWS_Kinesis_data_stream" /><category term="AWS" /><summary type="html">이 문서는 AWS Kinesis Data stream의 제약조건과 리샤딩에 대한 테스트 결과를 남기기 위해 작성하였다.</summary></entry><entry><title type="html">Kinesis Data Firehose에서 Amazon Elasticsearch와 S3 데이터 전달하기</title><link href="http://localhost:4000/aws_kinesis_firehose/firehose_to_es_s3/" rel="alternate" type="text/html" title="Kinesis Data Firehose에서 Amazon Elasticsearch와 S3 데이터 전달하기" /><published>2020-01-23T00:00:00+09:00</published><updated>2020-01-23T00:00:00+09:00</updated><id>http://localhost:4000/aws_kinesis_firehose/firehose_to_es_s3</id><content type="html" xml:base="http://localhost:4000/aws_kinesis_firehose/firehose_to_es_s3/">&lt;h1 id=&quot;테스트-목적&quot;&gt;테스트 목적&lt;/h1&gt;

&lt;p&gt;Amazon Kinesis Data Firehose - Delivery Stream의 destination을 Amazon Elasticsearch Service domain으로 지정하고 S3 backup 설정을 하여 Firehose로 전달된 데이터가 Amazon Elasticsaerch와 S3로 저장되는지 확인한다.&lt;/p&gt;

&lt;h1 id=&quot;테스트-환경&quot;&gt;테스트 환경&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 리전: 서울 리전&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 관련 서비스:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon Kinesis Data Firsehose&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon Elasticsearch Service(이하 Amazon ES)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon S3&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                             +----------------------+
  +---------+                |  Event-1 - Stream-1  |                 +--------+
  | Sources |---------------&amp;gt;|         ...          |----------------&amp;gt;| AWS S3 |
  +---------+ data records   |  Event-N - Stream-N  |        backup   +--------+
                             +----------------------+                   Bucket
                                 Delivery Streams
                                  (Event Stream)
                                        |                             +---------------+
                                        |                             | Elasticsearch |
                                        +----------------------------&amp;gt;| Cluster       |&amp;lt;---&amp;gt;[Kibana]
                                                            indexing  +---------------+      dashboard

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;테스트-환경-구성&quot;&gt;테스트 환경 구성&lt;/h1&gt;

&lt;h2 id=&quot;amazon-es-도메인&quot;&gt;Amazon ES 도메인&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;도메인 명:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Elasticsearch 6.5.4&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;인스턴스 구성&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;인스턴스 유형 : t2.small.elasticsearch (vCPU 1, Memory 2GiB)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;인스턴스 개수 : 2&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;인스턴스별 일반 EBS(SSD) 10GB 각 1개&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 인덱스 : interest_service_click2&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;kinesis-data-firehose-delivery-stream-생성&quot;&gt;Kinesis Data Firehose Delivery Stream 생성&lt;/h2&gt;

&lt;p&gt;테스트용 Delivery Stream을 아래와 같은 설정으로 생성하였다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Delivery Stream name :&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Index : interest_service_click2&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Type : isc&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;No index rotation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Backup S3 bucket :&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Delivery Stream buffer conditions for Elasticsearch&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;buffer size : 5 MB&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;buffer interval : 60 seconds&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;IAM role(역할)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Amazon ES 도메인 ARN -&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;시스템팀에 생성 요청.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Type 설정에서 _doc 를 입력하면 Elasticsearch index는 _ 로 시작할 수 없다 라는 에러 메시지가 발생한다.&lt;br /&gt;
_doc는 Elasticsearch에서 index 생성시 따로 type을 지정하지 않으면 만들어지는 것이다.&lt;/p&gt;

&lt;p&gt;위 에러발생을 회피하기 위해 기존에 만들었던 interest_service_click index를 사용하지 않고 신규 index를 생성하여 테스트 하는 것으로 테스트 방법을 변경하였다.&lt;br /&gt;
명시적으로 Type명도 isc라는 것으로 설정하였다.&lt;/p&gt;

&lt;p&gt;Delivery Stream의 buffer interval을 최소값인 60초로 한 것은 Amazon ES와 S3로 데이터가 저장되는 것을 가능한 빠르게 확인하기 위하여 설정한 것이다.&lt;/p&gt;

&lt;h1 id=&quot;테스트--delivery-stream-데이터-전송-및-저장-확인&quot;&gt;테스트 : Delivery Stream 데이터 전송 및 저장 확인&lt;/h1&gt;

&lt;h2 id=&quot;delivery-stream-전송-테스트-및-확인&quot;&gt;Delivery Stream 전송 테스트 및 확인&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Data Firehose의 ‘Test with demo data’ 기능으로 테스트 데이터를 delivery stream에 넣고 구성데로 전달되는지 확인하였다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Amazon ES 테스트 도메인에 interest_service_click2 인덱스가 생성되고 search api로 데이터가 조회되는 것을 확인하였다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ curl -XGET '{es_domain}/interest_service_click2/_search'
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Amazon S3의 test 버킷에 2019/04/30/06/ 경로 아래로 테스트 데이터들이 저장된 것을 확인하였다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;test-1-2019-04-30-06-26-00-9c948a08-f91a-4ba2-922d-408623ea0ddf
test-1-2019-04-30-06-27-00-aca38977-b723-47df-b557-488e9d583f93
test-1-2019-04-30-06-28-06-e0b3d645-e27d-451e-b812-33013a5aa57a
    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;firehose-api-사용하여-delivery-stream에-테스트-데이터-전송-및-저장-확인&quot;&gt;Firehose API 사용하여 Delivery Stream에 테스트 데이터 전송 및 저장 확인&lt;/h2&gt;

&lt;p&gt;커스텀 데이터를 Firehose Delivery Stream에 전송하여 Amazon ES와 S3 저장되는지 테스트한다.&lt;br /&gt;
아래와 같은 데이터를 Firehose Delivery Stream에 전송한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;user_id&quot;: &quot;Aster-Kotlin-Sapphire-564&quot;,
    &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
    &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
    &quot;device_manufacturer&quot;: &quot;LG&quot;,
    &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;,
    &quot;device_model&quot;: &quot;LM-G710N&quot;,
    &quot;device_os&quot;: &quot;Android&quot;,
    &quot;device_os_number&quot;: &quot;8.0&quot;,
    &quot;event&quot;: &quot;interest_service_click&quot;,
    &quot;interest_id&quot;: 1201,
    &quot;index&quot;: 1,
    &quot;interest_name&quot;: &quot;1&quot;,
    &quot;interest_service_id&quot;: null,
    &quot;interest_service_type&quot;: &quot;1&quot;,
    &quot;interest_service_name&quot;: &quot;1&quot;,
    &quot;timestamp&quot;: &quot;2019-04-30T07:30:00Z&quot;
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;aws config, credential 설정 관련된 부분은 &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/cli-chap-configure.html&quot;&gt;AWS CLI 구성&lt;/a&gt; 문서를 참고하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 가상환경을 구성하고 boto3 라이브러리를 설치한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ python3 -m venv ./boto3_venv
$ source ./boto3_venv/bin/activate
$ pip3 install boto3

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래와 같은 파이썬 코드로 Data Firehose의 Delivery Stream에 데이터를 전송하여 테스트 하였다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import boto3
import json
import sys



def get_firehose_client():
    # Any clients created from this session will use credentials
    # from the [test_profile] section of ~/.aws/credentials
    # with test_profile profile.
    session = boto3.Session(profile_name=&quot;test_profile&quot;)
    firehose = session.client(&quot;firehose&quot;)
    return firehose


# Test list up Delivery Streams
def list_delivery_streams():
    firehose = get_firehose_client()

    print(&quot;List Delivery Streams&quot;)
    response = firehose.list_delivery_streams(DeliveryStreamType=&quot;DirectPut&quot;)
    print(response[&quot;DeliveryStreamNames&quot;])


# Test Record send to Delivery Stream
def put_record_to_delivery_stream():
    print(&quot;Put record to Delivery Stream&quot;)

    test_data = {
        &quot;user_id&quot;: &quot;Aster-Kotlin-Sapphire-564&quot;,
        &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
        &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
        &quot;device_manufacturer&quot;: &quot;LG&quot;,
        &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;,
        &quot;device_model&quot;: &quot;LM-G710N&quot;,
        &quot;device_os&quot;: &quot;Android&quot;,
        &quot;device_os_number&quot;: &quot;8.0&quot;,
        &quot;event&quot;: &quot;interest_service_click&quot;,
        &quot;interest_id&quot;: 1201,
        &quot;index&quot;: 1,
        &quot;interest_name&quot;: &quot;1&quot;,
        &quot;interest_service_id&quot;: None,
        &quot;interest_service_type&quot;: &quot;1&quot;,
        &quot;interest_service_name&quot;: &quot;1&quot;,
        &quot;timestamp&quot;: &quot;2019-04-30T07:30:00Z&quot;
    }

    firehose = get_firehose_client()

    response = firehose.put_record(
        DeliveryStreamName=&quot;test&quot;,
        Record={&quot;Data&quot;: json.dumps(test_data, ensure_ascii=False)}
    )

    print(response)


def batch_record_to_delivery_stream():
    print(&quot;Put batch records to Delivery Stream&quot;)

    test_data_list = [
        {
            &quot;user_id&quot;: &quot;Aster-Kotlin-Sapphire-564&quot;,
            &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
            &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
            &quot;device_manufacturer&quot;: &quot;LG&quot;, &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;, &quot;device_model&quot;: &quot;LM-G710N&quot;, &quot;device_os&quot;: &quot;Android&quot;, &quot;device_os_number&quot;: &quot;8.0&quot;,
            &quot;event&quot;: &quot;interest_service_click&quot;,
            &quot;interest_id&quot;: 1101,
            &quot;index&quot;: 1,
            &quot;interest_name&quot;: &quot;2&quot;, &quot;interest_service_id&quot;: None, &quot;interest_service_type&quot;: &quot;4&quot;,&quot;interest_service_name&quot;: &quot;4&quot;,
            &quot;timestamp&quot;: &quot;2019-05-03T00:20:00Z&quot;
        },
        {
            &quot;user_id&quot;: &quot;Aster-Kotlin-Sapphire-564&quot;,
            &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
            &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
            &quot;device_manufacturer&quot;: &quot;LG&quot;, &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;, &quot;device_model&quot;: &quot;LM-G710N&quot;, &quot;device_os&quot;: &quot;Android&quot;, &quot;device_os_number&quot;: &quot;8.0&quot;,
            &quot;event&quot;: &quot;interest_service_click&quot;,
            &quot;interest_id&quot;: 1301,
            &quot;index&quot;: 1,
            &quot;interest_name&quot;: &quot;55&quot;, &quot;interest_service_id&quot;: None, &quot;interest_service_type&quot;: &quot;5&quot;,&quot;interest_service_name&quot;: &quot;7&quot;,
            &quot;timestamp&quot;: &quot;2019-05-03T00:50:00Z&quot;
        },
        {
            &quot;user_id&quot;: &quot;Aster-Kotlin-Sapphire-564&quot;,
            &quot;app_version&quot;: &quot;v1.5.16(90)&quot;,
            &quot;device_id&quot;: &quot;a03cd3d6-0b14-46e1-a2c8-18b1c86cf738&quot;,
            &quot;device_manufacturer&quot;: &quot;LG&quot;, &quot;device_name&quot;: &quot;LG G7 ThinQ&quot;, &quot;device_model&quot;: &quot;LM-G710N&quot;, &quot;device_os&quot;: &quot;Android&quot;, &quot;device_os_number&quot;: &quot;8.0&quot;,
            &quot;event&quot;: &quot;interest_service_click&quot;,
            &quot;interest_id&quot;: 1201,
            &quot;index&quot;: 1,
            &quot;interest_name&quot;: &quot;1&quot;, &quot;interest_service_id&quot;: None, &quot;interest_service_type&quot;: &quot;1&quot;,&quot;interest_service_name&quot;: &quot;1&quot;,
            &quot;timestamp&quot;: &quot;2019-05-03T01:15:00Z&quot;
        }
    ]

    # Delivery Stream에 batch로 넣을 데이터 구성
    records_list = list()
    for test_data in test_data_list:
        records_list.append({&quot;Data&quot;: json.dumps(test_data, ensure_ascii=False)})

    firehose = get_firehose_client()

    response = firehose.put_record_batch(
        DeliveryStreamName=&quot;test&quot;,
        Records=records_list
    )

    print(response)


def main():
    arg = sys.argv[1:]
    if &quot;list&quot; in arg:
        list_delivery_streams()
    elif &quot;put&quot; in arg:
        put_record_to_delivery_stream()
    elif &quot;batch&quot; in arg:
        batch_record_to_delivery_stream()
    else:
        print(&quot;Unsupported test operation&quot;)
        print(&quot;Supported operations : ['list', 'put', 'batch']&quot;)



if __name__ == &quot;__main__&quot;:
    main()

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;put_record() 메소드를 사용한 단일 데이터 전달과 put_record_batch() 메소드를 사용한 여러개의 데이터 전달에 대하여 동작을 테스트하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;테스트-결과&quot;&gt;테스트 결과&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Kinesis Data Firehose의 Delivery Stream 구성에서 destination을 Amazon ES, backup all data를 S3로 설정한 구성이 예상대로 데이터를 전달받아 저장하는 것을 확인하였다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;테스트 데이터의 형상은 Delivery Stream 동작테스트를 위해 전송했던 demo data와 다른 것이다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;특별히 mapping 정보를 변경하지 않고 테스트 데이터를 Delivery Stream 전송하면 demo data에 의해 생성되었던 ics type의 mapping정보에 없던 새로운 필드가 추가되어 데이터가 저장되는 것이 확인되었다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Delivery Stream의 buffer interval 설정에 따른 데이터 전달 방식을 확인하였다. record put이 성공적으로 되어도 바로 Amazon ES나 S3로 데이터가 전달되지 않고 지연시간이 발생할 수 있음을 확인하였다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;참고자료&quot;&gt;참고자료&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.aws.amazon.com/firehose/latest/dev/basic-create.html&quot;&gt;https://docs.aws.amazon.com/firehose/latest/dev/basic-create.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation&quot;&gt;https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/controlling-access.html&quot;&gt;https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/controlling-access.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/test-drive-firehose.html#test-drive-destination-elasticsearch&quot;&gt;https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/test-drive-firehose.html#test-drive-destination-elasticsearch&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/firehose.html&quot;&gt;https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/firehose.html&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.bhargavnunna.com/index.php/2017/10/11/data-analysis-on-aws-part-1-1/&quot;&gt;http://blog.bhargavnunna.com/index.php/2017/10/11/data-analysis-on-aws-part-1-1/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/ko/elasticsearch-service/pricing/&quot;&gt;https://aws.amazon.com/ko/elasticsearch-service/pricing/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="AWS_Kinesis_firehose" /><category term="AWS_s3" /><category term="Elasticsearch" /><summary type="html">Amazon Kinesis Data Firehose - Delivery Stream의 destination을 Amazon Elasticsearch Service domain으로 지정하고 S3 backup 설정을 하여 Firehose로 전달된 데이터가 Amazon Elasticsaerch와 S3로 저장되는지 확인한다.</summary></entry><entry><title type="html">Fluentd의 Read from head option에 대해 알아보기</title><link href="http://localhost:4000/fluentd/fluentd_file_created_time/" rel="alternate" type="text/html" title="Fluentd의 Read from head option에 대해 알아보기" /><published>2020-01-22T00:00:00+09:00</published><updated>2020-01-22T00:00:00+09:00</updated><id>http://localhost:4000/fluentd/fluentd_file_created_time</id><content type="html" xml:base="http://localhost:4000/fluentd/fluentd_file_created_time/">&lt;h1 id=&quot;테스트-목적&quot;&gt;테스트 목적&lt;/h1&gt;

&lt;p&gt;Fluentd(이하 td-agent)로 로그를 수집할 때 디렉터리 워치로 파일 로그를 수집하는 경우가 있다. (예시 : 날짜별 파일 로그 수집)&lt;/p&gt;

&lt;p&gt;이러한 경우에서 로그 파일 생성 시점에 따라 다음과 같은 케이스로 분류할 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;파일 생성 시점과 로그 저장 시점이 다른 경우&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;파일 생성 시점과 로그 저장 시점이 같은 경우&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 로그 파일 생성 시점에 관하여 추가적인 설명을 하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;파일 생성과 로그 저장이 다른 시점에 이루어지는 경우&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;로그 파일이 생성이 된다. 이후에 로그가 발생하면 파일에 저장한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;커널 명령으로 표현하면 다음과 같다.&lt;/p&gt;
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ touch log_file.log
$ echo &quot;log_test_1&quot; &amp;gt;&amp;gt; log_file.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;파일 생성과 로그 저장이 같은 시점에 이루어지는 경우&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;로그가 발생하면 파일 생성과 동시에 로그를 저장한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;커널 명령으로 표현하면 다음과 같다.&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;log_test_1&quot; &amp;gt; log_file.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 테스트는 로그 파일 생성 시점에 따른 케이스별로 테스트하며 td-agent가 동작을 확인하는 데에 목적이 있다.&lt;/p&gt;

&lt;h1 id=&quot;테스트-환경&quot;&gt;테스트 환경&lt;/h1&gt;

&lt;p&gt;테스트 환경은 다음과 같다.&lt;/p&gt;

&lt;p&gt;OS : macOS Mojave 10.14.6&lt;/p&gt;

&lt;p&gt;td-agent : v1.0.2&lt;/p&gt;

&lt;h1 id=&quot;테스트에-필요한-사전-지식&quot;&gt;테스트에 필요한 사전 지식&lt;/h1&gt;

&lt;p&gt;다음과 같은 사전 지식이 필요하다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Source Plug In : tail&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Match Plug In : match&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;td-agent 관련 정보&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;td-agent 실행, 종료&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;td-agent 동작 로그 확인 방법&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;td-agent 설정 경로&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;source-plug-in--tail&quot;&gt;Source Plug In : tail&lt;/h2&gt;

&lt;p&gt;다음 링크들을 참고 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.fluentd.org/input/tail&quot;&gt;Fluentd - Input Plugin : tail&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://jangseongwoo.github.io/fluentd/fluentd_filter_plugin_operation_check/&quot;&gt;Fluentd - plugin에 대한 학습 정리&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://jangseongwoo.github.io/fluentd/fluentd_output_plugin_operation_check/&quot;&gt;Fluentd(td-agent) output plugin&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;match-plug-in--match&quot;&gt;Match Plug In : match&lt;/h2&gt;

&lt;p&gt;다음 링크들을 참고 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.fluentd.org/output/file&quot;&gt;Fluentd - Output Plugin : file&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://jangseongwoo.github.io/fluentd/fluentd_filter_plugin_operation_check/&quot;&gt;Fluentd - plugin에 대한 학습 정리&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;td-agent-관련-정보&quot;&gt;td-agent 관련 정보&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://jangseongwoo.github.io/fluentd/fluentd_basic/&quot;&gt;Fluentd 기초 사용법&lt;/a&gt;을 확인하여 td-agent 기초 동작을 확인하면 된다.&lt;/p&gt;

&lt;h2 id=&quot;td-agent의-파일-감지-여부와-read_from_head-옵션&quot;&gt;td-agent의 파일 감지 여부와 read_from_head 옵션&lt;/h2&gt;

&lt;p&gt;“td-agent가 수집하려는 파일의 감지 여부(position file에 저장되는 정보)”와 “read_from_head 옵션”에 따라 “파일에서 로그수집 시작위치”가 다르다.&lt;/p&gt;

&lt;p&gt;이와 관련하여 혼동되는 부분이 있을 것이라 생각되어 다음과 같이 정리한다.&lt;/p&gt;

&lt;p&gt;수집하려는 파일의 감지여부&lt;/p&gt;

&lt;p&gt;read_from_file 옵션&lt;/p&gt;

&lt;p&gt;로그수집 시작위치&lt;/p&gt;

&lt;p&gt;O&lt;/p&gt;

&lt;p&gt;true&lt;/p&gt;

&lt;p&gt;파일의 bottom부터 수집&lt;/p&gt;

&lt;p&gt;O&lt;/p&gt;

&lt;p&gt;false&lt;/p&gt;

&lt;p&gt;파일의 bottom부터 수집&lt;/p&gt;

&lt;p&gt;X&lt;/p&gt;

&lt;p&gt;true&lt;/p&gt;

&lt;p&gt;파일의 head부터 수집&lt;/p&gt;

&lt;p&gt;X&lt;/p&gt;

&lt;p&gt;false&lt;/p&gt;

&lt;p&gt;파일의 bottom부터 수집&lt;/p&gt;

&lt;p&gt;더 자세한 내용은 &lt;a href=&quot;https://docs.fluentd.org/input/tail#read_from_head&quot;&gt;Fluentd - Input Plugin : tail : read_from_head&lt;/a&gt;에서 확인한다.&lt;/p&gt;

&lt;h1 id=&quot;테스트-과정&quot;&gt;테스트 과정&lt;/h1&gt;

&lt;p&gt;td-agent의 설정 파일의 경로를 다음과 같이 지정한다.&lt;/p&gt;

&lt;p&gt;/Users/kevin/dev/fluentd/test/file_creation_time/config/td-agent.conf&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat /opt/td-agent/usr/sbin/td-agent

... 중략 ...

ENV[&quot;FLUENT_CONF&quot;]=&quot;/Users/kevin/dev/fluentd/test/file_creation_time/config/td-agent.conf&quot;

... 중략 ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;td-agent 설정 파일을 다음과 같이 수정하고 실행한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat config/td-agent.log 
&amp;lt;source&amp;gt;
  @type tail
  tag file_creation_time
  path /Users/kevin/dev/fluentd/test/file_creation_time/source/*
  pos_file /Users/kevin/dev/fluentd/test/file_creation_time/pos/pos_file.pos
  &amp;lt;parse&amp;gt;
    @type none
  &amp;lt;/parse&amp;gt;
  refresh_interval 5s
&amp;lt;/source&amp;gt;
&amp;lt;match file_creation_time*&amp;gt;
  @type file
  path /Users/kevin/dev/fluentd/test/file_creation_time/match/${tag}_output
  add_path_suffix true
  path_suffix &quot;.log&quot;
  append true
  &amp;lt;buffer tag&amp;gt;
    flush_mode interval
    flush_interval 10s
  &amp;lt;/buffer&amp;gt;
  &amp;lt;format&amp;gt;
    @type out_file
    output_tag false
    output_time true
  &amp;lt;/format&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo launchctl load td-agent.plist
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;케이스--파일-생성-시점과-로그-저장-시점이-다른-경우&quot;&gt;케이스 : 파일 생성 시점과 로그 저장 시점이 다른 경우&lt;/h2&gt;

&lt;p&gt;다음과 같이 입력용 빈 파일을 생성한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ touch source/different_time_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음과 같이 td-agent가 파일 생성을 인지한 것을 확인한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat /var/log/td-agent/td-agent.log

... 중략 ...

2019-08-29 17:40:32 +0900 [info]: #0 following tail of /Users/kevin/dev/fluentd/test/file_creation_time/source/different_time_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음과 같이 입력용 파일에 로그를 저장한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;log_test_line1&quot; &amp;gt;&amp;gt; source/differnt_time_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력용 파일을 확인하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tail -10f match/file_creation_time_output.log
2019-08-29T17:41:03+09:00	{&quot;message&quot;:&quot;log_test_line1&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다시 한번 다음과 같이 파일에 로그를 저장한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;log_test_line2&quot; &amp;gt;&amp;gt; source/differnt_time_input.log
$ echo &quot;log_test_line3&quot; &amp;gt;&amp;gt; source/differnt_time_input.log
$ echo &quot;log_test_line4&quot; &amp;gt;&amp;gt; source/differnt_time_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력용 파일을 확인하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tail -10f match/file_creation_time_output.log
2019-08-29T17:41:03+09:00	{&quot;message&quot;:&quot;log_test_line1&quot;}
2019-08-29T17:49:58+09:00	{&quot;message&quot;:&quot;log_test_line2&quot;}
2019-08-29T17:50:04+09:00	{&quot;message&quot;:&quot;log_test_line3&quot;}
2019-08-29T17:50:10+09:00	{&quot;message&quot;:&quot;log_test_line4&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;테스트 결과를 정리하면 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;입력용 빈 파일을 생성하면 td-agent 파일 생성을 인지한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;입력용 파일 생성 이후 로그를 저장하면 출력용 파일에 로그의 형식은 바뀌지만  로그가 저장된다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;케이스--파일-생성-시점과-로그-저장-시점이-같은-경우&quot;&gt;케이스 : 파일 생성 시점과 로그 저장 시점이 같은 경우&lt;/h2&gt;

&lt;p&gt;다음과 같이 로그를 파일에 저장한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;log_test_line1&quot; &amp;gt; source/same_time_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;별도의 파일 생성없이 로그를 저장하여도 파일이 생성되고 로그가 저장된다.&lt;/p&gt;

&lt;p&gt;다음과 같이 td-agent가 파일 생성을 인지한 것을 확인한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat /var/log/td-agent/td-agent.log

... 중략 ...

2019-08-29 18:10:42 +0900 [info]: #0 following tail of /Users/kevin/dev/fluentd/test/file_creation_time/source/same_time_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력용 파일에 로그가 저장 되었는지 확인 하였지만 로그가 저장된 것을 확인할 수 없다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tail -10f match/file_creation_time_output.log

... 중략 ...

same_time_input.log의 로그 내용이 출력되지 않음.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음과 같이 입력용 파일에 로그를 저장한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;log_test_line2&quot; &amp;gt;&amp;gt; source/same_time_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력용 파일을 확인하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tail -10f match/file_creation_time_output.log

... 중략 ...

2019-08-29T18:16:57+09:00	{&quot;message&quot;:&quot;log_test_line2&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다시 한번 다음과 같이 파일에 로그를 저장한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;log_test_line3&quot; &amp;gt;&amp;gt; source/same_time_input.log
$ echo &quot;log_test_line4&quot; &amp;gt;&amp;gt; source/same_time_input.log
$ echo &quot;log_test_line5&quot; &amp;gt;&amp;gt; source/same_time_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력용 파일을 확인하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tail -10f match/file_creation_time_output.log

... 중략 ...

2019-08-29T18:16:57+09:00	{&quot;message&quot;:&quot;log_test_line2&quot;}
2019-08-29T18:18:40+09:00	{&quot;message&quot;:&quot;log_test_line3&quot;}
2019-08-29T18:18:43+09:00	{&quot;message&quot;:&quot;log_test_line4&quot;}
2019-08-29T18:18:46+09:00	{&quot;message&quot;:&quot;log_test_line5&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;테스트 결과를 정리하면 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;입력용 파일을 생성과 동시에 로그를 저장하면 td-agent는 파일 생성은 인지하지만 출력용 파일을 확인 하였을 때 로그가 저장되지 않는다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;입력용 파일 생성 이후 로그를 저장하면 출력용 파일에 로그의 형식은 바뀌지만  로그가 저장된다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;케이스--파일-생성-시점과-로그-저장-시점이-같은-경우-read_from_head-옵션을-true로-설정하였을-때&quot;&gt;케이스 : 파일 생성 시점과 로그 저장 시점이 같은 경우 (read_from_head 옵션을 true로 설정하였을 때)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;케이스 : 파일 생성 시점과 로그 저장 시점이 같은 경우&lt;/strong&gt;와 동일한 설정, 과정에서 Source plug in - tail의 read_from_head 옵션을 변경하고 td-agent의 동작을 확인한다.&lt;/p&gt;

&lt;p&gt;td-agent 설정 파일에 다음과 같은 옵션을 source plugin에 추가한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;read_from_head = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat config/td-agent.log 
&amp;lt;source&amp;gt;
  @type tail
  tag file_creation_time
  read_from_head = true 
  path /Users/kevin/dev/fluentd/test/file_creation_time/source/*
  pos_file /Users/kevin/dev/fluentd/test/file_creation_time/pos/pos_file.pos
  &amp;lt;parse&amp;gt;
    @type none
  &amp;lt;/parse&amp;gt;
  refresh_interval 5s
&amp;lt;/source&amp;gt;
&amp;lt;match file_creation_time*&amp;gt;
  @type file
  path /Users/kevin/dev/fluentd/test/file_creation_time/match/${tag}_output
  add_path_suffix true
  path_suffix &quot;.log&quot;
  append true
  &amp;lt;buffer tag&amp;gt;
    flush_mode interval
    flush_interval 10s
  &amp;lt;/buffer&amp;gt;
  &amp;lt;format&amp;gt;
    @type out_file
    output_tag false
    output_time true
  &amp;lt;/format&amp;gt;
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;td-agent를 실행한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo launchctl load td-agent.plist
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음과 같이 로그를 파일에 저장한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;log_test_line1&quot; &amp;gt; source/same_time_head_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음과 같이 td-agent가 파일 생성을 인지한 것을 확인한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cat /var/log/td-agent/td-agent.log

... 중략 ...

019-08-29 18:39:16 +0900 [info]: #0 following tail of /Users/kevin/dev/fluentd/test/file_creation_time/source/same_time_head_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력용 파일을 확인하면 로그가 저장된 것을 알 수 있다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tail -10f match/file_creation_time_output.log

... 중략 ...

2019-08-29T18:39:16+09:00	{&quot;message&quot;:&quot;log_test_line1&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다시 한번 다음과 같이 파일에 로그를 저장한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;log_test_line2&quot; &amp;gt;&amp;gt; source/same_time_head_input.log
$ echo &quot;log_test_line3&quot; &amp;gt;&amp;gt; source/same_time_head_input.log
$ echo &quot;log_test_line4&quot; &amp;gt;&amp;gt; source/same_time_head_input.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력용 파일을 확인하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ tail -10f match/file_creation_time_output.log

... 중략 ...

2019-08-29T18:39:16+09:00	{&quot;message&quot;:&quot;log_test_line1&quot;}
2019-08-29T18:44:52+09:00	{&quot;message&quot;:&quot;log_test_line2&quot;}
2019-08-29T18:44:58+09:00	{&quot;message&quot;:&quot;log_test_line3&quot;}
2019-08-29T18:45:02+09:00	{&quot;message&quot;:&quot;log_test_line4&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;테스트 결과를 정리하면 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;read_from_head = true인 경우에는 입력용 파일을 생성과 동시에 로그를 저장하면 td-agent는 파일 생성을 인지하고 출력용 파일에도 로그가 저장된다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;입력용 파일에 로그를 저장하면 출력용 파일에 로그의 형식은 바뀌지만  로그가 저장된다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;테스트-결과&quot;&gt;테스트 결과&lt;/h1&gt;

&lt;p&gt;테스트 결과를 정리하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;파일 생성 시점과 로그 저장 시점이 다른 경우&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;입력용 로그 파일에 저장된 로그는 출력용 파일에 저장됨을 알 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;파일 생성 시점과 로그 저장 시점이 다른 경우&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;입력용 로그 파일 생성 시점의 저장된 로그는 출력용 파일에 저장되지 않는다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;생성이후 저장된 로그는 출력용 파일에 저장된다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;만약 파일 생성 시점의 로그를 저장하고자 한다면 Input plug in - tail의 read_from_head 옵션은 true로 한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>kelpin</name><email>seongwoo.dev@gmail.com</email></author><category term="Fluentd" /><summary type="html">Fluentd의 Read from head option이 있다. 이해할 때 헷갈리는 부분이 있어 정확한 이해를 위해 로컬에서 직접 시나리오를 만들어 테스트를 진행해본다.</summary></entry></feed>